{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports, config and logging server",
   "id": "638db9e71feb8f9a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Standard library\n",
    "import ast\n",
    "from copy import deepcopy\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import mlflow\n",
    "from mlflow.pytorch import load_model\n",
    "\n",
    "import torchmetrics.functional.regression as R\n",
    "\n",
    "# Project-specific imports\n",
    "from default import *\n",
    "from config import DIRECTORY, PORT\n",
    "from tools import MLFlowSession\n",
    "from models.architecture import MLP\n",
    "from models.processing import StandardScaler\n",
    "from dataset import FixedPrattTrussDataset\n",
    "from losses import StiffnessToLoadLoss\n",
    "\n",
    "# Set random state and device\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "# Set working directory and figure directory\n",
    "%cd -q {PROJECT_HOME}\n",
    "figure_dir = os.path.join(os.getcwd(), '022025_experiment/figures')\n",
    "\n",
    "# Configure MLFlow server\n",
    "DIRECTORY = DIRECTORY['122']\n",
    "PORT = PORT['122']\n",
    "server = MLFlowSession(PORT=PORT, DIRECTORY=DIRECTORY)\n",
    "server.start()\n",
    "\n",
    "# Set dataset dirs\n",
    "bisupported = True\n",
    "n_input_dims = 64 if bisupported else 65\n",
    "n_output_dims = 29\n",
    "\n",
    "loss = 'pinn'\n",
    "\n",
    "train_dataset_dir = r\"data/dataset/pratt_truss_bridge_hyperstatic/2_member_ea\"\n",
    "test_dataset_dir = r\"data/dataset/pratt_truss_bridge_hyperstatic/test\"\n",
    "\n",
    "_validation_ds = FixedPrattTrussDataset(f\"{test_dataset_dir}/2_member_8192.hdf5\", bisupported=bisupported)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training procedure",
   "id": "d3ecda6bc7a8ea9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pratt_stiffness_matrix(H: float, L: float, EA: torch.DoubleTensor):\n",
    "    H2 = H ** 2\n",
    "    L2 = L ** 2\n",
    "    D2_3_2 = (H ** 2 + L ** 2) ** (3 / 2)\n",
    "    HL = H * L\n",
    "\n",
    "    EA_L = EA / L\n",
    "    EA_H = EA / H\n",
    "\n",
    "    EA_L2_D2_3_2 = EA * L2 / D2_3_2\n",
    "    EA_HL_D2_3_2 = EA * HL / D2_3_2\n",
    "    EA_H2_D2_3_2 = EA * H2 / D2_3_2\n",
    "\n",
    "    k = torch.eye(32).repeat((len(EA), 1, 1))\n",
    "\n",
    "    k[:, 2, 2] = EA_L[:, 0] + EA_L[:, 1]\n",
    "    k[:, 2, 4] = -EA_L[:, 1]\n",
    "    k[:, 3, 3] = EA_H[:, 14]\n",
    "    k[:, 3, 31] = -EA_H[:, 14]\n",
    "    k[:, 4, 2] = -EA_L[:, 1]\n",
    "    k[:, 4, 4] = EA_L[:, 1] + EA_L[:, 2] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 5] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 4, 6] = -EA_L[:, 2]\n",
    "    k[:, 4, 30] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 31] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 4] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 5] = EA_H[:, 15] + EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 5, 29] = -EA_H[:, 15]\n",
    "    k[:, 5, 30] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 31] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 6, 4] = -EA_L[:, 2]\n",
    "    k[:, 6, 6] = EA_L[:, 2] + EA_L[:, 3] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 7] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 6, 8] = -EA_L[:, 3]\n",
    "    k[:, 6, 28] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 29] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 6] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 7] = EA_H[:, 16] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 7, 27] = -EA_H[:, 16]\n",
    "    k[:, 7, 28] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 29] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 8, 6] = -EA_L[:, 3]\n",
    "    k[:, 8, 8] = EA_L[:, 3] + EA_L[:, 4] + EA_L2_D2_3_2[:, 24] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 9] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 10] = -EA_L[:, 4]\n",
    "    k[:, 8, 22] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 23] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 26] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 8, 27] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 8] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 9] = EA_H[:, 17] + EA_H2_D2_3_2[:, 24] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 22] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 23] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 25] = -EA_H[:, 17]\n",
    "    k[:, 9, 26] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 27] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 10, 8] = -EA_L[:, 4]\n",
    "    k[:, 10, 10] = EA_L[:, 4] + EA_L[:, 5] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 11] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 10, 12] = -EA_L[:, 5]\n",
    "    k[:, 10, 20] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 21] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 10] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 11] = EA_H[:, 18] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 20] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 21] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 23] = -EA_H[:, 18]\n",
    "    k[:, 12, 10] = -EA_L[:, 5]\n",
    "    k[:, 12, 12] = EA_L[:, 5] + EA_L[:, 6] + EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 13] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 12, 14] = -EA_L[:, 6]\n",
    "    k[:, 12, 18] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 19] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 12] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 13] = EA_H[:, 19] + EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 18] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 19] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 21] = -EA_H[:, 19]\n",
    "    k[:, 14, 12] = -EA_L[:, 6]\n",
    "    k[:, 14, 14] = EA_L[:, 6] + EA_L[:, 7]\n",
    "    k[:, 14, 16] = -EA_L[:, 7]\n",
    "    k[:, 15, 15] = EA_H[:, 20]\n",
    "    k[:, 15, 19] = -EA_H[:, 20]\n",
    "    k[:, 16, 14] = -EA_L[:, 7]\n",
    "    k[:, 16, 16] = EA_L[:, 7] + EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 16, 18] = -EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 16, 19] = EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 18, 12] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 18, 13] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 18, 16] = -EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 18, 18] = EA_L[:, 8] + EA_L2_D2_3_2[:, 27] + EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 18, 19] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 18, 20] = -EA_L[:, 8]\n",
    "    k[:, 19, 12] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 19, 13] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 19, 15] = -EA_H[:, 20]\n",
    "    k[:, 19, 16] = EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 19, 18] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 19, 19] = EA_H[:, 20] + EA_H2_D2_3_2[:, 27] + EA_H2_D2_3_2[:, 28]\n",
    "    k[:, 20, 10] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 11] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 18] = -EA_L[:, 8]\n",
    "    k[:, 20, 20] = EA_L[:, 8] + EA_L[:, 9] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 21] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 22] = -EA_L[:, 9]\n",
    "    k[:, 21, 10] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 11] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 21, 13] = -EA_H[:, 19]\n",
    "    k[:, 21, 20] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 21] = EA_H[:, 19] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 22, 8] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 9] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 20] = -EA_L[:, 9]\n",
    "    k[:, 22, 22] = EA_L[:, 9] + EA_L[:, 10] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 23] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 24] = -EA_L[:, 10]\n",
    "    k[:, 23, 8] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 9] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 23, 11] = -EA_H[:, 18]\n",
    "    k[:, 23, 22] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 23] = EA_H[:, 18] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 24, 22] = -EA_L[:, 10]\n",
    "    k[:, 24, 24] = EA_L[:, 10] + EA_L[:, 11]\n",
    "    k[:, 24, 26] = -EA_L[:, 11]\n",
    "    k[:, 25, 9] = -EA_H[:, 17]\n",
    "    k[:, 25, 25] = EA_H[:, 17]\n",
    "    k[:, 26, 8] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 9] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 24] = -EA_L[:, 11]\n",
    "    k[:, 26, 26] = EA_L[:, 11] + EA_L[:, 12] + EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 27] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 28] = -EA_L[:, 12]\n",
    "    k[:, 27, 7] = -EA_H[:, 16]\n",
    "    k[:, 27, 8] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 9] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 27, 26] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 27] = EA_H[:, 16] + EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 28, 6] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 7] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 26] = -EA_L[:, 12]\n",
    "    k[:, 28, 28] = EA_L[:, 12] + EA_L[:, 13] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 29] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 30] = -EA_L[:, 13]\n",
    "    k[:, 29, 5] = -EA_H[:, 15]\n",
    "    k[:, 29, 6] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 7] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 29, 28] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 29] = EA_H[:, 15] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 30, 4] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 5] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 30, 28] = -EA_L[:, 13]\n",
    "    k[:, 30, 30] = EA_L[:, 13] + EA_L2_D2_3_2[:, 21] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 31] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 3] = -EA_H[:, 14]\n",
    "    k[:, 31, 4] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 5] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 31, 30] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 31] = EA_H[:, 14] + EA_H2_D2_3_2[:, 21] + EA_H2_D2_3_2[:, 22]\n",
    "\n",
    "    return k"
   ],
   "id": "e16a822474612f46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.jit.script\n",
    "def pratt_stiffness_matrix(EA: torch.Tensor) -> torch.Tensor:\n",
    "    H2 = 56.25\n",
    "    L2 = 56.25\n",
    "    D2_3_2 = (112.5) ** (3 / 2)\n",
    "    HL = 56.25\n",
    "\n",
    "    EA_L = EA / 7.5\n",
    "    EA_H = EA / 7.5\n",
    "\n",
    "    EA_L2_D2_3_2 = EA * L2 / D2_3_2\n",
    "    EA_HL_D2_3_2 = EA * HL / D2_3_2\n",
    "    EA_H2_D2_3_2 = EA * H2 / D2_3_2\n",
    "\n",
    "    k = torch.zeros((EA.shape[0], 32, 32), dtype=EA.dtype, device=EA.device)\n",
    "\n",
    "    k[:, 0, 0] = 1.\n",
    "    k[:, 1, 1] = 1.\n",
    "    k[:, 16, 16] = 1.\n",
    "    k[:, 17, 17] = 1.\n",
    "\n",
    "    k[:, 2, 2] = EA_L[:, 0] + EA_L[:, 1]\n",
    "    k[:, 2, 4] = -EA_L[:, 1]\n",
    "    k[:, 3, 3] = EA_H[:, 14]\n",
    "    k[:, 3, 31] = -EA_H[:, 14]\n",
    "    k[:, 4, 2] = -EA_L[:, 1]\n",
    "    k[:, 4, 4] = EA_L[:, 1] + EA_L[:, 2] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 5] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 4, 6] = -EA_L[:, 2]\n",
    "    k[:, 4, 30] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 31] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 4] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 5] = EA_H[:, 15] + EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 5, 29] = -EA_H[:, 15]\n",
    "    k[:, 5, 30] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 31] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 6, 4] = -EA_L[:, 2]\n",
    "    k[:, 6, 6] = EA_L[:, 2] + EA_L[:, 3] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 7] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 6, 8] = -EA_L[:, 3]\n",
    "    k[:, 6, 28] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 29] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 6] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 7] = EA_H[:, 16] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 7, 27] = -EA_H[:, 16]\n",
    "    k[:, 7, 28] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 29] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 8, 6] = -EA_L[:, 3]\n",
    "    k[:, 8, 8] = EA_L[:, 3] + EA_L[:, 4] + EA_L2_D2_3_2[:, 24] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 9] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 10] = -EA_L[:, 4]\n",
    "    k[:, 8, 22] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 23] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 26] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 8, 27] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 8] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 9] = EA_H[:, 17] + EA_H2_D2_3_2[:, 24] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 22] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 23] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 25] = -EA_H[:, 17]\n",
    "    k[:, 9, 26] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 27] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 10, 8] = -EA_L[:, 4]\n",
    "    k[:, 10, 10] = EA_L[:, 4] + EA_L[:, 5] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 11] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 10, 12] = -EA_L[:, 5]\n",
    "    k[:, 10, 20] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 21] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 10] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 11] = EA_H[:, 18] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 20] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 21] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 23] = -EA_H[:, 18]\n",
    "    k[:, 12, 10] = -EA_L[:, 5]\n",
    "    k[:, 12, 12] = EA_L[:, 5] + EA_L[:, 6] + EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 13] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 12, 14] = -EA_L[:, 6]\n",
    "    k[:, 12, 18] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 19] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 12] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 13] = EA_H[:, 19] + EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 18] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 19] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 21] = -EA_H[:, 19]\n",
    "    k[:, 14, 12] = -EA_L[:, 6]\n",
    "    k[:, 14, 14] = EA_L[:, 6] + EA_L[:, 7]\n",
    "\n",
    "    k[:, 15, 15] = EA_H[:, 20]\n",
    "    k[:, 15, 19] = -EA_H[:, 20]\n",
    "\n",
    "    k[:, 18, 12] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 18, 13] = -EA_HL_D2_3_2[:, 27]\n",
    "\n",
    "    k[:, 18, 18] = EA_L[:, 8] + EA_L2_D2_3_2[:, 27] + EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 18, 19] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 18, 20] = -EA_L[:, 8]\n",
    "    k[:, 19, 12] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 19, 13] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 19, 15] = -EA_H[:, 20]\n",
    "\n",
    "    k[:, 19, 18] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 19, 19] = EA_H[:, 20] + EA_H2_D2_3_2[:, 27] + EA_H2_D2_3_2[:, 28]\n",
    "    k[:, 20, 10] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 11] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 18] = -EA_L[:, 8]\n",
    "    k[:, 20, 20] = EA_L[:, 8] + EA_L[:, 9] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 21] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 22] = -EA_L[:, 9]\n",
    "    k[:, 21, 10] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 11] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 21, 13] = -EA_H[:, 19]\n",
    "    k[:, 21, 20] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 21] = EA_H[:, 19] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 22, 8] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 9] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 20] = -EA_L[:, 9]\n",
    "    k[:, 22, 22] = EA_L[:, 9] + EA_L[:, 10] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 23] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 24] = -EA_L[:, 10]\n",
    "    k[:, 23, 8] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 9] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 23, 11] = -EA_H[:, 18]\n",
    "    k[:, 23, 22] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 23] = EA_H[:, 18] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 24, 22] = -EA_L[:, 10]\n",
    "    k[:, 24, 24] = EA_L[:, 10] + EA_L[:, 11]\n",
    "    k[:, 24, 26] = -EA_L[:, 11]\n",
    "    k[:, 25, 9] = -EA_H[:, 17]\n",
    "    k[:, 25, 25] = EA_H[:, 17]\n",
    "    k[:, 26, 8] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 9] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 24] = -EA_L[:, 11]\n",
    "    k[:, 26, 26] = EA_L[:, 11] + EA_L[:, 12] + EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 27] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 28] = -EA_L[:, 12]\n",
    "    k[:, 27, 7] = -EA_H[:, 16]\n",
    "    k[:, 27, 8] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 9] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 27, 26] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 27] = EA_H[:, 16] + EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 28, 6] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 7] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 26] = -EA_L[:, 12]\n",
    "    k[:, 28, 28] = EA_L[:, 12] + EA_L[:, 13] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 29] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 30] = -EA_L[:, 13]\n",
    "    k[:, 29, 5] = -EA_H[:, 15]\n",
    "    k[:, 29, 6] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 7] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 29, 28] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 29] = EA_H[:, 15] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 30, 4] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 5] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 30, 28] = -EA_L[:, 13]\n",
    "    k[:, 30, 30] = EA_L[:, 13] + EA_L2_D2_3_2[:, 21] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 31] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 3] = -EA_H[:, 14]\n",
    "    k[:, 31, 4] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 5] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 31, 30] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 31] = EA_H[:, 14] + EA_H2_D2_3_2[:, 21] + EA_H2_D2_3_2[:, 22]\n",
    "\n",
    "    return k"
   ],
   "id": "ef339cef302a2ca7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def u_from_x(x, n_panels=8):\n",
    "    batch_size = len(x)\n",
    "    u = torch.zeros((batch_size, 4 * n_panels), device=x.device)\n",
    "    u[:, 2:2 * n_panels + 1] = x[:, :2 * (n_panels - 1) + 1]\n",
    "    u[:, 2 * (n_panels + 1):] = x[:, 2 * (n_panels - 1) + 1:4 * n_panels - 3]\n",
    "    return u.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def q_from_x_q(x, q, n_panels=8):\n",
    "    q = q.squeeze(-1)\n",
    "    q[:, np.arange(3, 2 * n_panels, 2)] = x[:, 4 * n_panels - 3: 5 * n_panels - 4]\n",
    "\n",
    "    return q.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def train_step(model, batch, input_scaler, target_scaler, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    input, target, _, u, q = batch\n",
    "    input, target = input.to(device), target.to(device)\n",
    "    u, q = u.to(device), q.to(device)\n",
    "    q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "    z_input = input_scaler.transform(input)\n",
    "    z_target = target_scaler.transform(target)\n",
    "\n",
    "    z_target_pred = model(z_input)\n",
    "    target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "    #k_pred = pratt_stiffness_matrix(7.5, 7.5, target_pred).to(device)\n",
    "    k_pred = pratt_stiffness_matrix(target_pred).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(k_pred * 1e-6,\n",
    "                     u_from_x(input, 8) * 1e3,\n",
    "                     q_from_x_q(input, q, 8) * 1e-3)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validation(model, batch, input_scaler, target_scaler, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input, target, _, u, q = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        u, q = u.to(device), q.to(device)\n",
    "        q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "        z_input = input_scaler.transform(input)\n",
    "        z_target = target_scaler.transform(target)\n",
    "\n",
    "        z_target_pred = model(z_input)\n",
    "        target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "        #k_pred = pratt_stiffness_matrix(7.5, 7.5, target_pred).to(device)\n",
    "        k_pred = pratt_stiffness_matrix(target_pred).to(device)\n",
    "\n",
    "        loss = criterion(k_pred * 1e-6,\n",
    "                         u_from_x(input, 8) * 1e3,\n",
    "                         q_from_x_q(input, q, 8) * 1e-3)\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(model, target_pred, z_target_pred, target, z_target):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        r2 = R.r2_score(z_target_pred, z_target)\n",
    "        if r2.isinf():  # Switch to 64 bits in case of overflow\n",
    "            r2 = R.r2_score(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64))\n",
    "        mape = R.mean_absolute_percentage_error(target_pred, target)\n",
    "        rmse = R.mean_squared_error(target_pred * 1e-6, target * 1e-6, squared=False)\n",
    "        if rmse.isinf():  # Switch to 64 bits in case of overflow\n",
    "            rmse = R.mean_squared_error(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64),\n",
    "                                        squared=False)\n",
    "\n",
    "    return {'r2': r2, 'mape': mape, 'rmse_MN': rmse}\n",
    "\n",
    "\n",
    "def log_epoch(train_metrics, val_metrics, epoch):\n",
    "    metrics = dict()\n",
    "    metrics.update({f'train_{k}': v for k, v in train_metrics.items()})\n",
    "    metrics.update({f'val_{k}': v for k, v in val_metrics.items()})\n",
    "\n",
    "    mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "\n",
    "def log_model(name, model, signature, metadata=None):\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=name,\n",
    "        signature=signature,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "\n",
    "def console_log(epoch, train_metrics, val_metrics):\n",
    "    print(f\">> Epoch {epoch + 1:4d}\", end='  ')\n",
    "    print(f\"TRAIN\", end='   ')\n",
    "    metric_names = {k for k in train_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = train_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "\n",
    "    print(\"  ||  \", end='')\n",
    "    print(f\"VALIDATION\", end='   ')\n",
    "    metric_names = {k for k in val_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = val_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "    print()\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion,\n",
    "          log_step=10):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    train_dl = DataLoader(train_dataset, train_batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, val_batch_size, shuffle=False)\n",
    "\n",
    "    input_scaler = StandardScaler(train_dataset[0][0].__len__()).to(device)\n",
    "    target_scaler = StandardScaler(train_dataset[0][1].__len__()).to(device)\n",
    "\n",
    "    # Train the scaler\n",
    "    input, target = None, None\n",
    "    for batch in train_dl:\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        input_scaler.partial_fit(input)\n",
    "        target_scaler.partial_fit(target)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(),\n",
    "                                              input_scaler.transform(input).cpu().detach().numpy())\n",
    "    log_model('input_scaler', input_scaler, signature=signature)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(target.cpu().detach().numpy(),\n",
    "                                              target_scaler.transform(target).cpu().detach().numpy())\n",
    "    log_model('target_scaler', target_scaler, signature=signature)\n",
    "\n",
    "    best_val_metric = {\n",
    "        'mape': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'rmse_MN': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'r2': {model: None, 'value': -np.inf, 'epoch': -1}\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_metrics = {}\n",
    "        val_metrics = {}\n",
    "        for batch in train_dl:\n",
    "            train_metrics_epoch = train_step(model, batch, input_scaler, target_scaler, optimizer, criterion)\n",
    "            for k, m in train_metrics_epoch.items():\n",
    "                if k not in train_metrics: train_metrics[k] = []\n",
    "                train_metrics[k].append(m)\n",
    "\n",
    "        for batch in val_dl:\n",
    "            val_metrics_epoch = validation(model, batch, input_scaler, target_scaler, criterion)\n",
    "            for k, m in val_metrics_epoch.items():\n",
    "                if k not in val_metrics: val_metrics[k] = []\n",
    "                val_metrics[k].append(m)\n",
    "\n",
    "        # Compute the mean on GPU  -> Faster for batch\n",
    "        train_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                         train_metrics.items()}\n",
    "        val_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                       val_metrics.items()}\n",
    "\n",
    "        log_epoch(train_metrics, val_metrics, epoch + 1)\n",
    "\n",
    "        negative_metrics = {'r2'}  # Set of metrics which are better when higher\n",
    "\n",
    "        for k, v in val_metrics.items():\n",
    "            f = 1 if k not in negative_metrics else -1\n",
    "            if f * best_val_metric[k]['value'] >= f * v:\n",
    "                best_val_metric[k] = {'model': deepcopy(model), 'value': v.item(), 'epoch': epoch + 1}\n",
    "\n",
    "        if (log_step < 0): continue\n",
    "        if (epoch % log_step == 0):\n",
    "            console_log(epoch + 1, train_metrics, val_metrics)\n",
    "\n",
    "    input, target, _, _, _ = train_dl.__iter__().__next__()\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(), target.cpu().detach().numpy())\n",
    "    for k, v in best_val_metric.items():\n",
    "        metric = v['value']\n",
    "        epoch = v['epoch']\n",
    "        log_model(f\"{k}_model\", v['model'], signature=signature, metadata={'metric': metric, 'epoch': epoch + 1})\n",
    "\n",
    "\n",
    "def trial_routine(run_name, train_routine, mlp_params, train_dataset, val_dataset, train_batch_size,\n",
    "                  val_batch_size, n_epoch, optimizer, lr, criterion, fold, log_step=10, log_params=None):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Model initialization\n",
    "        model = MLP(**mlp_params)\n",
    "\n",
    "        # Model information logging\n",
    "        capacity = sum(np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        if log_params is not None:\n",
    "            mlflow.log_params(log_params)\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params({\n",
    "            'n_hidden_layers': len(mlp_params['hidden_dims']),\n",
    "            'hidden_layers_size': mlp_params['hidden_dims'][0],\n",
    "            'capacity': capacity,\n",
    "            'n_epoch': n_epoch,\n",
    "            'val_batch_size': val_batch_size,\n",
    "            'train_batch_size': train_batch_size,\n",
    "            'train_size': train_dataset.__len__(),\n",
    "            'val_size': val_dataset.__len__(),\n",
    "            'k-fold': fold,\n",
    "            'optimizer': optimizer.__name__,\n",
    "            'learning_rate': f\"{lr:.1e}\",\n",
    "            'criterion': criterion.__name__,\n",
    "        })\n",
    "\n",
    "        # Run the training with the configuration\n",
    "        train_routine(model, train_dataset, val_dataset,\n",
    "                      train_batch_size, val_batch_size,\n",
    "                      n_epoch, optimizer(model.parameters(), lr=lr), criterion(), log_step=log_step)"
   ],
   "id": "cc02212926ddb095",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot(results, configs, metrics, labels, logs=None, xlim=None, ylim=None, figsize=(10, 10)):\n",
    "    if not isinstance(metrics, list):\n",
    "        metrics = [metrics]\n",
    "    if logs is None:\n",
    "        logs = [True] * len(metrics)\n",
    "    elif not isinstance(logs, list):\n",
    "        logs = [logs] * len(metrics)\n",
    "\n",
    "    cmap = mpl.colormaps['tab10']\n",
    "    c = cmap(np.linspace(0, 1, len(configs)))\n",
    "\n",
    "    if len(metrics) == 1:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "        axs = [ax]\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows=int(np.ceil(len(metrics) / 2)), ncols=2, figsize=figsize)\n",
    "        axs = [ax for row in axs for ax in row]\n",
    "\n",
    "    for i, (metric, log) in enumerate(zip(metrics, logs)):\n",
    "        ax = axs[i]\n",
    "        # Plot the data but collect the handles for the legend\n",
    "        config_handles = []\n",
    "        for i, conf in enumerate(configs):\n",
    "            # Store only the validation line handles for the legend\n",
    "            l = len(results[conf][f'train_{metric}'])\n",
    "            h = ax.plot(np.arange(l), results[conf][f'train_{metric}'], alpha=.5, ls='--', lw=1, c=c[i])[0]\n",
    "            h2 = ax.plot(np.arange(l), results[conf][f'val_{metric}'], ls='-', lw=1, c=c[i])[0]\n",
    "            config_handles.append(h2)\n",
    "\n",
    "        # Create custom handles for the line style legend\n",
    "        line_style_handles = [\n",
    "            Line2D([0], [0], color='black', lw=1, ls='--', alpha=0.5, label='Training'),\n",
    "            Line2D([0], [0], color='black', lw=1, ls='-', label='Validation'),\n",
    "            Line2D([0], [0], color='black', alpha=0, lw=1, ls='-')\n",
    "        ]\n",
    "\n",
    "        # Get the current position and size of the axis\n",
    "        box = ax.get_position()\n",
    "        # Reduce the width of the axis to make room for the legend\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "        # Combine both sets of handles and labels\n",
    "        all_handles = line_style_handles + config_handles\n",
    "        all_labels = ['Training', 'Validation', ''] + labels\n",
    "\n",
    "        # Create a single legend with both line styles and configurations\n",
    "        plt.figlegend(all_handles, all_labels, loc='center left', bbox_to_anchor=(1, .5),\n",
    "                      title=\"Legend\")\n",
    "\n",
    "        ax.set_title(f\"Evolution of {metric} during training\")\n",
    "        if log:\n",
    "            ax.set_yscale('log')\n",
    "        ax.set_ylabel(f\"{metric} [/]\")\n",
    "        ax.set_xlabel(\"epoch [/]\")\n",
    "\n",
    "        if xlim: ax.set_xlim(*xlim)\n",
    "        if ylim: ax.set_ylim(*ylim)\n",
    "\n",
    "    fig.tight_layout(h_pad=2, w_pad=7.5)\n",
    "    # Adjust right padding to make room for the legend\n",
    "    plt.show()"
   ],
   "id": "82e00a6fd2b113ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyper-parameter tuning",
   "id": "6c8687dcdc80cc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "kfold = 5\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "ds = FixedPrattTrussDataset(f\"{train_dataset_dir}/train_4096.hdf5\", bisupported=bisupported)\n",
    "mlflow.set_tracking_uri(uri=server.url())"
   ],
   "id": "d29ab63ae696a235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model capacity",
   "id": "9a07b3136850acad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_experiment(\"capacity\")\n",
    "\n",
    "n_layers_values = [2, 3, 4, 5]\n",
    "n_neurons_values = [65, 70, 80, 100, 120]\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for n_layers in n_layers_values:\n",
    "        for n_neurons in n_neurons_values:\n",
    "            for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "                hidden_dims = [n_neurons for _ in range(n_layers)]\n",
    "                train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "                future = executor.submit(trial_routine, None, train,\n",
    "                                         {\n",
    "                                             'input_dim': n_input_dims,\n",
    "                                             'hidden_dims': hidden_dims,\n",
    "                                             'output_dim': n_output_dims,\n",
    "                                             'activation': \"relu\",\n",
    "                                             'activation_params': None,\n",
    "                                             'dropout': 0.0,\n",
    "                                             'batch_norm': False,\n",
    "                                             'layer_norm': False,\n",
    "                                             'normalization_params': None,\n",
    "                                             'output_activation': None,\n",
    "                                             'output_activation_params': None,\n",
    "                                         },\n",
    "                                         train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                         N_EPOCH,\n",
    "                                         torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': loss})\n",
    "                futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "a2d9c17d69f70e37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"capacity\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "layers_combinations = set()\n",
    "for n_layers in runs_df['params.n_hidden_layers'].unique():\n",
    "    for layer_size in runs_df['params.hidden_layers_size'].unique():\n",
    "        layers_combinations.add((n_layers, layer_size))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in layers_combinations}\n",
    "for n, size in layers_combinations:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == loss) &\n",
    "        (runs_df['params.n_hidden_layers'] == n) &\n",
    "        (runs_df['params.hidden_layers_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[(n, size)][metric_name].append(\n",
    "                [metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "f11fdbf460404de2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "configs_by_val_mape = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = configs_by_val_mape\n",
    "\n",
    "configs = sorted(configs)\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [str([int(x) for x in cfg]) for cfg in configs]\n",
    "\n",
    "plot(results, configs, ['loss', 'mape', 'r2', 'rmse_MN'], labels, logs=[True, True, False, True])"
   ],
   "id": "d6443ded5e8d757a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pareto front technique\n",
    "best_mape = configs_by_val_mape[0][0]\n",
    "candidates = [x[1] for x in filter(lambda x: x[0] <= best_mape * 1.02, configs_by_val_mape)]\n",
    "\n",
    "filtered_results = {k: results[k] for k in candidates}\n",
    "\n",
    "configs_by_val_rmse = sorted([(np.min(v['val_rmse_MN']), k) for k, v in filtered_results.items()])\n",
    "best_candidate = [int(x) for x in configs_by_val_rmse[0][1]]\n",
    "best_hidden_dims = [best_candidate[1]] * best_candidate[0]\n",
    "\n",
    "print(f\"Best candidate is: {best_candidate} according to the pareto front.\")"
   ],
   "id": "3289a9ee01387f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "to_delete = [\n",
    "    'n_layers_values', 'n_neurons_values', 'executor', 'futures', 'n_layers', 'n_neurons',\n",
    "    'fold', 'train_idx', 'val_idx', 'hidden_dims', 'train_dataset', 'validation_dataset',\n",
    "    'future', 'experiment', 'runs_df', 'cols', 'metrics_names', 'layers_combinations',\n",
    "    'client', 'results', 'n', 'size', 'run_ids', 'run_id', 'metric_name', 'k',\n",
    "    'configs_by_val_mape', 'configs', 'labels', 'best_mape', 'candidates',\n",
    "    'filtered_results', 'configs_by_val_rmse', 'best_candidate'\n",
    "]\n",
    "\n",
    "for var in to_delete:\n",
    "    try:\n",
    "        globals().pop(var, None)\n",
    "    except KeyError:\n",
    "        continue\n"
   ],
   "id": "f2aa6f586f3fe4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Activation function",
   "id": "93b132f2bf6959c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_experiment(\"activation_function\")\n",
    "\n",
    "activation_values = ['relu', 'gelu', 'tanh', 'sigmoid',\n",
    "                     'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']\n",
    "activation_params_values = [None, None, None, None,\n",
    "                            {'negative_slope': 5e-1}, {'negative_slope': 1e-1}, {'negative_slope': 5e-2},\n",
    "                            {'negative_slope': 1e-2}]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for activation, activation_params in zip(activation_values, activation_params_values):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': n_input_dims,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': n_output_dims,\n",
    "                                         'activation': activation,\n",
    "                                         'activation_params': activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': loss})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "48e9454b1488126a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"activation_function\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "activations_combinations = set()\n",
    "for m in runs_df['params.activation'].unique():\n",
    "    for n in runs_df[runs_df['params.activation'] == m]['params.activation_params'].unique():\n",
    "        activations_combinations.add((m, n))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in activations_combinations}\n",
    "for k in activations_combinations:\n",
    "    (act, params) = k\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == loss) &\n",
    "        (runs_df['params.activation'] == act) &\n",
    "        (runs_df['params.activation_params'] == params)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[k][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "610d0dd31d4cf72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs_by_val_mape = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "\n",
    "configs = [x[1] for x in configs_by_val_mape]\n",
    "\n",
    "labels = [f\"[{cfg[0]}]\" if cfg[1] == 'None' else f\"[{cfg[0]}, {cfg[1]}]\" for cfg in configs]\n",
    "\n",
    "plot(results, configs, ['loss', 'mape', 'r2', 'rmse_MN'], labels, logs=[True, True, False, True])"
   ],
   "id": "797b80941e1b28fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pareto front technique\n",
    "best_mape = configs_by_val_mape[0][0]\n",
    "candidates = [x[1] for x in filter(lambda x: x[0] <= best_mape * 1.02, configs_by_val_mape)]\n",
    "\n",
    "filtered_results = {k: results[k] for k in candidates}\n",
    "\n",
    "configs_by_val_rmse = sorted([(np.min(v['val_rmse_MN']), k) for k, v in filtered_results.items()])\n",
    "\n",
    "best_candidate = configs_by_val_rmse[0][1]\n",
    "best_activation = best_candidate[0]\n",
    "best_activation_params = ast.literal_eval(best_candidate[1])\n",
    "\n",
    "print(f\"Best candidate is: {best_candidate} according to the pareto front.\")"
   ],
   "id": "a05bc042f94ecbd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "to_delete = [\n",
    "    'activation_values', 'activation_params_values', 'executor', 'futures',\n",
    "    'activation', 'activation_params', 'fold', 'train_idx', 'val_idx',\n",
    "    'train_dataset', 'validation_dataset', 'future', 'experiment', 'runs_df',\n",
    "    'cols', 'metrics_names', 'activations_combinations', 'client', 'results',\n",
    "    'k', 'act', 'params', 'run_ids', 'run_id', 'metric_name', 'configs_by_val_mape',\n",
    "    'configs', 'labels', 'best_mape', 'candidates', 'filtered_results',\n",
    "    'configs_by_val_rmse', 'best_candidate'\n",
    "]\n",
    "\n",
    "for var in to_delete:\n",
    "    try:\n",
    "        del globals()[var]\n",
    "    except KeyError:\n",
    "        pass"
   ],
   "id": "72a8ffbfe2d20498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Learning rate",
   "id": "ff16b8442c555745"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "%%capture\n",
    "mlflow.set_experiment(\"learning_rate\")\n",
    "\n",
    "lr_values = sorted(np.hstack([f * np.logspace(-4, -3, 2) for f in [1, 2.5, 5, 7.5]]))\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for LR in lr_values:\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': n_input_dims,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': n_output_dims,\n",
    "                                         'activation': best_activation,\n",
    "                                         'activation_params': best_activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': loss})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "261074916b695ec0"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"learning_rate\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "learning_rates = set(runs_df['params.learning_rate'].unique())\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in learning_rates}\n",
    "for lr in learning_rates:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == loss) &\n",
    "        (runs_df['params.learning_rate'] == lr)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[lr][metric_name].append([metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "66836cf2332455bc"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "configs_by_val_mape = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs_by_val_mape]\n",
    "\n",
    "labels = [f\"{float(c):.1e}\" for c in configs]\n",
    "\n",
    "plot(results, configs, ['loss', 'mape', 'r2', 'rmse_MN'], labels, logs=[True, True, False, True])"
   ],
   "id": "b622b76d0cac22a8"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "# Pareto front technique\n",
    "best_mape = configs_by_val_mape[0][0]\n",
    "candidates = [x[1] for x in filter(lambda x: x[0] <= best_mape * 1.02, configs_by_val_mape)]\n",
    "\n",
    "filtered_results = {k: results[k] for k in candidates}\n",
    "\n",
    "configs_by_val_rmse = sorted([(np.min(v['val_rmse_MN']), k) for k, v in filtered_results.items()])\n",
    "\n",
    "best_candidate = configs_by_val_rmse[0][1]\n",
    "best_learning_rate = float(best_candidate)\n",
    "\n",
    "print(f\"Best candidate is: {best_candidate} according to the pareto front.\")"
   ],
   "id": "b2b65ea8767b808c"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "to_delete = [\n",
    "    'lr_values', 'executor', 'futures', 'LR', 'fold', 'train_idx', 'val_idx',\n",
    "    'train_dataset', 'validation_dataset', 'future', 'experiment', 'runs_df',\n",
    "    'cols', 'metrics_names', 'learning_rates', 'client', 'results',\n",
    "    'lr', 'run_ids', 'run_id', 'metric_name', 'k', 'configs_by_val_mape',\n",
    "    'configs', 'labels', 'best_mape', 'candidates', 'filtered_results',\n",
    "    'configs_by_val_rmse', 'best_candidate'\n",
    "]\n",
    "\n",
    "for var in to_delete:\n",
    "    try:\n",
    "        del globals()[var]\n",
    "    except KeyError:\n",
    "        pass"
   ],
   "id": "52746a24728474e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_learning_rate = 1e-3",
   "id": "c114a7c7a254e923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training final model",
   "id": "92724e82b0249ad5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "36dfbb4315680527"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_experiment(\"training\")\n",
    "\n",
    "VAL_BATCH_SIZE = 8192\n",
    "N_EPOCH = 1_000\n",
    "log_step = -1\n",
    "\n",
    "sizes = [2 ** i for i in range(8, 15)]\n",
    "batch_size_values = [512 for _ in sizes]\n",
    "dataset_path_values = [f\"{train_dataset_dir}/train_{n}.hdf5\" for n in sizes]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, (dataset_path, TRAIN_BATCH_SIZE) in enumerate(zip(dataset_path_values, batch_size_values)):\n",
    "        size = sizes[i]\n",
    "        train_dataset = FixedPrattTrussDataset(dataset_path, bisupported=bisupported)\n",
    "        validation_dataset = _validation_ds\n",
    "        future = executor.submit(trial_routine, None, train,\n",
    "                                 {\n",
    "                                     'input_dim': n_input_dims,\n",
    "                                     'hidden_dims': best_hidden_dims,\n",
    "                                     'output_dim': n_output_dims,\n",
    "                                     'activation': best_activation,\n",
    "                                     'activation_params': best_activation_params,\n",
    "                                     'dropout': 0.0,\n",
    "                                     'batch_norm': False,\n",
    "                                     'layer_norm': False,\n",
    "                                     'normalization_params': None,\n",
    "                                     'output_activation': None,\n",
    "                                     'output_activation_params': None\n",
    "                                 },\n",
    "                                 train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                 N_EPOCH,\n",
    "                                 torch.optim.Adam, best_learning_rate, StiffnessToLoadLoss,\n",
    "                                 -1, log_step, {'loss': loss, 'noise': 0.})\n",
    "        futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "4ea2176e20760243",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "sizes = set()\n",
    "for size in runs_df['params.train_size'].unique():\n",
    "    sizes.add(size)\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in sizes}\n",
    "for size in sizes:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == loss) &\n",
    "        (runs_df['params.train_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[size][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "b39e163a8719d41b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{int(size)}\" for size in configs]\n",
    "\n",
    "plot(results, configs, ['loss', 'mape', 'r2', 'rmse_MN'], labels, logs=[True, True, False, True])"
   ],
   "id": "fa529c6549b4d00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Noise sensitivity",
   "id": "c51a102fb7b734d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "for set_path, set_name in zip(\n",
    "    [f\"{test_dataset_dir}/uniform_8192.hdf5\",\n",
    "     f\"{test_dataset_dir}/category_8192.hdf5\",\n",
    "     f\"{test_dataset_dir}/member_8192.hdf5\",\n",
    "     f\"{test_dataset_dir}/mixed_8192.hdf5\"],\n",
    "    ['uniform_ea', 'category_ea', 'member_ea', 'mixed_ea']\n",
    "):\n",
    "    mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "    experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "    runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "    runs_df = runs_df[runs_df['params.loss'] == loss]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for f in np.linspace(0, .1, 6):\n",
    "        validation_ds = FixedPrattTrussDataset(\n",
    "            set_path,\n",
    "            f_noise_length=None,\n",
    "            f_noise_loads=lambda size: 1. + np.random.exponential(f / 2, size=size) * (\n",
    "                    (np.random.binomial(1, .5, size=size) * 2.) - 1),\n",
    "            f_noise_strain=lambda size: 1. + np.random.exponential(f / 2, size=size) * (\n",
    "                    (np.random.binomial(1, .5, size=size) * 2.) - 1),\n",
    "            f_noise_displacement=lambda size: 1. + np.random.exponential(f / 2, size=size) * (\n",
    "                    (np.random.binomial(1, .5, size=size) * 2.) - 1),\n",
    "            bisupported=bisupported\n",
    "        )\n",
    "\n",
    "        dl = DataLoader(validation_ds, batch_size=8192)\n",
    "\n",
    "        for i in range(len(runs_df[['artifact_uri', 'params.train_size']])):\n",
    "            artifact_uri = runs_df.iloc[i]['artifact_uri']\n",
    "            size = runs_df.iloc[i]['params.train_size']\n",
    "\n",
    "            uri = f\"{artifact_uri}/input_scaler/\"\n",
    "            input_scaler = load_model(uri)\n",
    "\n",
    "            uri = f\"{artifact_uri}/target_scaler/\"\n",
    "            target_scaler = load_model(uri)\n",
    "\n",
    "            uri = f\"{artifact_uri}/mape_model/\"\n",
    "            model = load_model(uri)\n",
    "\n",
    "            for batch in dl:\n",
    "                metrics = validation(model, batch, input_scaler, target_scaler, StiffnessToLoadLoss())\n",
    "            results.append((size, f, metrics))\n",
    "\n",
    "    mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "    mlflow.set_experiment(\"noise_sensitivity\")\n",
    "\n",
    "    df = pd.DataFrame([[results[i][0], results[i][1],\n",
    "                        results[i][2]['r2'].item(),\n",
    "                        results[i][2]['mape'].item(),\n",
    "                        results[i][2]['rmse_MN'].item(),\n",
    "                        results[i][2]['loss']]\n",
    "                       for i in range(len(results))], columns=['train_size', 'noise', 'r2', 'mape', 'rmse_MN', 'loss'])\n",
    "    df.sort_values(by=['train_size', 'noise'], axis=0, ignore_index=True, inplace=True)\n",
    "\n",
    "    for size in df.train_size.unique():\n",
    "        with mlflow.start_run():\n",
    "            df_2 = df[df['train_size'] == size]\n",
    "            # Model information logging\n",
    "            mlflow.log_params({\n",
    "                'train_size': size,\n",
    "                'loss': loss,\n",
    "                'test_set': set_name\n",
    "            })\n",
    "            for i in range(len(df_2)):\n",
    "                mlflow.log_metrics(\n",
    "                    dict(df_2.iloc[i][1:]),\n",
    "                    step=i\n",
    "                )"
   ],
   "id": "d2722cb187306c04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Closing the server",
   "id": "b91d7ec2f81cdc4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "server.terminate()",
   "id": "261f3e1dbef3f311",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a183026dbee4d6b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
