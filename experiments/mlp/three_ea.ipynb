{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:26:43.824321Z",
     "start_time": "2025-05-09T21:26:43.821045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from default import *\n",
    "\n",
    "PORT = 5010\n",
    "%cd -q {PROJECT_HOME}"
   ],
   "id": "d4bf42058f22f4aa",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T21:24:54.846904Z",
     "start_time": "2025-05-09T21:24:52.890742Z"
    }
   },
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "figure_dir = os.getcwd() + '/022025_experiment/figures'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from models.architecture import MLP\n",
    "from models.processing import StandardScaler\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mlflow.pytorch import load_model\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "\n",
    "from losses import StiffnessToLoadLoss\n",
    "\n",
    "import ast\n",
    "\n",
    "import torchmetrics.functional.regression as R\n",
    "from dataset import FixedPrattTrussDatasetThreeTargets\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from tools.mlflow import BasicDataset\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:28:11.996418Z",
     "start_time": "2025-05-09T21:28:11.994376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_total_EA_vector(x):\n",
    "    y = torch.zeros(x.shape[0], 29, dtype=torch.float32)\n",
    "\n",
    "    y[:, 0:14] = x[:, 0].unsqueeze(1)\n",
    "    y[:, 21] = x[:, 0]\n",
    "    y[:, 28] = x[:, 0]\n",
    "    y[:, 14:21] = x[:, 1].unsqueeze(1)\n",
    "    y[:, 22:28] = x[:, 2].unsqueeze(1)\n",
    "\n",
    "    return y"
   ],
   "id": "c605b0275d66be2",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:24:57.449646Z",
     "start_time": "2025-05-09T21:24:57.429882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pratt_stiffness_matrix(H: float, L: float, EA: torch.DoubleTensor):\n",
    "    H2 = H ** 2\n",
    "    L2 = L ** 2\n",
    "    D2_3_2 = (H ** 2 + L ** 2) ** (3 / 2)\n",
    "    HL = H * L\n",
    "\n",
    "    EA_L = EA / L\n",
    "    EA_H = EA / H\n",
    "\n",
    "    EA_L2_D2_3_2 = EA * L2 / D2_3_2\n",
    "    EA_HL_D2_3_2 = EA * HL / D2_3_2\n",
    "    EA_H2_D2_3_2 = EA * H2 / D2_3_2\n",
    "\n",
    "    k = torch.eye(32).repeat((len(EA), 1, 1))\n",
    "\n",
    "    k[:, 2, 2] = EA_L[:, 0] + EA_L[:, 1]\n",
    "    k[:, 2, 4] = -EA_L[:, 1]\n",
    "    k[:, 3, 3] = EA_H[:, 14]\n",
    "    k[:, 3, 31] = -EA_H[:, 14]\n",
    "    k[:, 4, 2] = -EA_L[:, 1]\n",
    "    k[:, 4, 4] = EA_L[:, 1] + EA_L[:, 2] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 5] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 4, 6] = -EA_L[:, 2]\n",
    "    k[:, 4, 30] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 4, 31] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 4] = -EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 5] = EA_H[:, 15] + EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 5, 29] = -EA_H[:, 15]\n",
    "    k[:, 5, 30] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 5, 31] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 6, 4] = -EA_L[:, 2]\n",
    "    k[:, 6, 6] = EA_L[:, 2] + EA_L[:, 3] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 7] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 6, 8] = -EA_L[:, 3]\n",
    "    k[:, 6, 28] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 6, 29] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 6] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 7] = EA_H[:, 16] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 7, 27] = -EA_H[:, 16]\n",
    "    k[:, 7, 28] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 7, 29] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 8, 6] = -EA_L[:, 3]\n",
    "    k[:, 8, 8] = EA_L[:, 3] + EA_L[:, 4] + EA_L2_D2_3_2[:, 24] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 9] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 10] = -EA_L[:, 4]\n",
    "    k[:, 8, 22] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 8, 23] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 8, 26] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 8, 27] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 8] = -EA_HL_D2_3_2[:, 24] + EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 9] = EA_H[:, 17] + EA_H2_D2_3_2[:, 24] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 22] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 9, 23] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 9, 25] = -EA_H[:, 17]\n",
    "    k[:, 9, 26] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 9, 27] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 10, 8] = -EA_L[:, 4]\n",
    "    k[:, 10, 10] = EA_L[:, 4] + EA_L[:, 5] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 11] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 10, 12] = -EA_L[:, 5]\n",
    "    k[:, 10, 20] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 10, 21] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 10] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 11] = EA_H[:, 18] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 20] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 11, 21] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 11, 23] = -EA_H[:, 18]\n",
    "    k[:, 12, 10] = -EA_L[:, 5]\n",
    "    k[:, 12, 12] = EA_L[:, 5] + EA_L[:, 6] + EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 13] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 12, 14] = -EA_L[:, 6]\n",
    "    k[:, 12, 18] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 12, 19] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 12] = EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 13] = EA_H[:, 19] + EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 18] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 13, 19] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 13, 21] = -EA_H[:, 19]\n",
    "    k[:, 14, 12] = -EA_L[:, 6]\n",
    "    k[:, 14, 14] = EA_L[:, 6] + EA_L[:, 7]\n",
    "    k[:, 14, 16] = -EA_L[:, 7]\n",
    "    k[:, 15, 15] = EA_H[:, 20]\n",
    "    k[:, 15, 19] = -EA_H[:, 20]\n",
    "    k[:, 16, 14] = -EA_L[:, 7]\n",
    "    k[:, 16, 16] = EA_L[:, 7] + EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 16, 18] = -EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 16, 19] = EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 18, 12] = -EA_L2_D2_3_2[:, 27]\n",
    "    k[:, 18, 13] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 18, 16] = -EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 18, 18] = EA_L[:, 8] + EA_L2_D2_3_2[:, 27] + EA_L2_D2_3_2[:, 28]\n",
    "    k[:, 18, 19] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 18, 20] = -EA_L[:, 8]\n",
    "    k[:, 19, 12] = -EA_HL_D2_3_2[:, 27]\n",
    "    k[:, 19, 13] = -EA_H2_D2_3_2[:, 27]\n",
    "    k[:, 19, 15] = -EA_H[:, 20]\n",
    "    k[:, 19, 16] = EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 19, 18] = EA_HL_D2_3_2[:, 27] - EA_HL_D2_3_2[:, 28]\n",
    "    k[:, 19, 19] = EA_H[:, 20] + EA_H2_D2_3_2[:, 27] + EA_H2_D2_3_2[:, 28]\n",
    "    k[:, 20, 10] = -EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 11] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 18] = -EA_L[:, 8]\n",
    "    k[:, 20, 20] = EA_L[:, 8] + EA_L[:, 9] + EA_L2_D2_3_2[:, 26]\n",
    "    k[:, 20, 21] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 20, 22] = -EA_L[:, 9]\n",
    "    k[:, 21, 10] = -EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 11] = -EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 21, 13] = -EA_H[:, 19]\n",
    "    k[:, 21, 20] = EA_HL_D2_3_2[:, 26]\n",
    "    k[:, 21, 21] = EA_H[:, 19] + EA_H2_D2_3_2[:, 26]\n",
    "    k[:, 22, 8] = -EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 9] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 20] = -EA_L[:, 9]\n",
    "    k[:, 22, 22] = EA_L[:, 9] + EA_L[:, 10] + EA_L2_D2_3_2[:, 25]\n",
    "    k[:, 22, 23] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 22, 24] = -EA_L[:, 10]\n",
    "    k[:, 23, 8] = -EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 9] = -EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 23, 11] = -EA_H[:, 18]\n",
    "    k[:, 23, 22] = EA_HL_D2_3_2[:, 25]\n",
    "    k[:, 23, 23] = EA_H[:, 18] + EA_H2_D2_3_2[:, 25]\n",
    "    k[:, 24, 22] = -EA_L[:, 10]\n",
    "    k[:, 24, 24] = EA_L[:, 10] + EA_L[:, 11]\n",
    "    k[:, 24, 26] = -EA_L[:, 11]\n",
    "    k[:, 25, 9] = -EA_H[:, 17]\n",
    "    k[:, 25, 25] = EA_H[:, 17]\n",
    "    k[:, 26, 8] = -EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 9] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 24] = -EA_L[:, 11]\n",
    "    k[:, 26, 26] = EA_L[:, 11] + EA_L[:, 12] + EA_L2_D2_3_2[:, 24]\n",
    "    k[:, 26, 27] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 26, 28] = -EA_L[:, 12]\n",
    "    k[:, 27, 7] = -EA_H[:, 16]\n",
    "    k[:, 27, 8] = EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 9] = -EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 27, 26] = -EA_HL_D2_3_2[:, 24]\n",
    "    k[:, 27, 27] = EA_H[:, 16] + EA_H2_D2_3_2[:, 24]\n",
    "    k[:, 28, 6] = -EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 7] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 26] = -EA_L[:, 12]\n",
    "    k[:, 28, 28] = EA_L[:, 12] + EA_L[:, 13] + EA_L2_D2_3_2[:, 23]\n",
    "    k[:, 28, 29] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 28, 30] = -EA_L[:, 13]\n",
    "    k[:, 29, 5] = -EA_H[:, 15]\n",
    "    k[:, 29, 6] = EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 7] = -EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 29, 28] = -EA_HL_D2_3_2[:, 23]\n",
    "    k[:, 29, 29] = EA_H[:, 15] + EA_H2_D2_3_2[:, 23]\n",
    "    k[:, 30, 4] = -EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 5] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 30, 28] = -EA_L[:, 13]\n",
    "    k[:, 30, 30] = EA_L[:, 13] + EA_L2_D2_3_2[:, 21] + EA_L2_D2_3_2[:, 22]\n",
    "    k[:, 30, 31] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 3] = -EA_H[:, 14]\n",
    "    k[:, 31, 4] = EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 5] = -EA_H2_D2_3_2[:, 22]\n",
    "    k[:, 31, 30] = EA_HL_D2_3_2[:, 21] - EA_HL_D2_3_2[:, 22]\n",
    "    k[:, 31, 31] = EA_H[:, 14] + EA_H2_D2_3_2[:, 21] + EA_H2_D2_3_2[:, 22]\n",
    "\n",
    "    return k"
   ],
   "id": "9d3df67643007b54",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:25:03.163940Z",
     "start_time": "2025-05-09T21:25:02.799693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the datasets\n",
    "_validation_ds = FixedPrattTrussDatasetThreeTargets(\"data/dataset/pratt_truss_bridge/member_ea/validation_8192.hdf5\")"
   ],
   "id": "eca9be5e9bd11146",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MSE Only",
   "id": "f6f32af142d5ba10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_step(model, batch, input_scaler, target_scaler, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    input, target, _, _, _ = batch\n",
    "    input, target = input.to(device), target.to(device)\n",
    "\n",
    "    z_input = input_scaler.transform(input)\n",
    "    z_target = target_scaler.transform(target)\n",
    "\n",
    "    z_target_pred = model(z_input)\n",
    "    target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(z_target_pred, z_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validation(model, batch, input_scaler, target_scaler, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        z_input = input_scaler.transform(input)\n",
    "        z_target = target_scaler.transform(target)\n",
    "\n",
    "        z_target_pred = model(z_input)\n",
    "        target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "        loss = criterion(z_target_pred, z_target)\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(model, target_pred, z_target_pred, target, z_target):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        r2 = R.r2_score(z_target_pred, z_target)\n",
    "        if r2.isinf():  # Switch to 64 bits in case of overflow\n",
    "            r2 = R.r2_score(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64))\n",
    "        mape = R.mean_absolute_percentage_error(target_pred, target)\n",
    "        rmse = R.mean_squared_error(target_pred * 1e-6, target * 1e-6, squared=False)\n",
    "        if rmse.isinf():  # Switch to 64 bits in case of overflow\n",
    "            rmse = R.mean_squared_error(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64),\n",
    "                                        squared=False)\n",
    "\n",
    "    return {'r2': r2, 'mape': mape, 'rmse_MN': rmse}\n",
    "\n",
    "\n",
    "def log_epoch(train_metrics, val_metrics, epoch):\n",
    "    metrics = dict()\n",
    "    metrics.update({f'train_{k}': v for k, v in train_metrics.items()})\n",
    "    metrics.update({f'val_{k}': v for k, v in val_metrics.items()})\n",
    "\n",
    "    mlflow.log_metrics(metrics, step=epoch + 1)\n",
    "\n",
    "\n",
    "def log_model(name, model, signature, metadata=None):\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=name,\n",
    "        signature=signature,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "\n",
    "def console_log(epoch, train_metrics, val_metrics):\n",
    "    print(f\">> Epoch {epoch + 1:4d}\", end='  ')\n",
    "    print(f\"TRAIN\", end='   ')\n",
    "    metric_names = {k for k in train_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = train_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "\n",
    "    print(\"  ||  \", end='')\n",
    "    print(f\"VALIDATION\", end='   ')\n",
    "    metric_names = {k for k in val_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = val_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "    print()\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion,\n",
    "          log_step=10):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    train_dl = DataLoader(train_dataset, train_batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, val_batch_size, shuffle=False)\n",
    "\n",
    "    input_scaler = StandardScaler(train_dataset[0][0].__len__()).to(device)\n",
    "    target_scaler = StandardScaler(train_dataset[0][1].__len__()).to(device)\n",
    "\n",
    "    # Train the scaler\n",
    "    input, target = None, None\n",
    "    for batch in train_dl:\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        input_scaler.partial_fit(input)\n",
    "        target_scaler.partial_fit(target)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(),\n",
    "                                              input_scaler.transform(input).cpu().detach().numpy())\n",
    "    log_model('input_scaler', input_scaler, signature=signature)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(target.cpu().detach().numpy(),\n",
    "                                              target_scaler.transform(target).cpu().detach().numpy())\n",
    "    log_model('target_scaler', target_scaler, signature=signature)\n",
    "\n",
    "    best_val_metric = {\n",
    "        'mape': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'rmse_MN': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'r2': {model: None, 'value': -np.inf, 'epoch': -1}\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_metrics = {}\n",
    "        val_metrics = {}\n",
    "        for batch in train_dl:\n",
    "            train_metrics_epoch = train_step(model, batch, input_scaler, target_scaler, optimizer, criterion)\n",
    "            for k, m in train_metrics_epoch.items():\n",
    "                if k not in train_metrics: train_metrics[k] = []\n",
    "                train_metrics[k].append(m)\n",
    "\n",
    "        for batch in val_dl:\n",
    "            val_metrics_epoch = validation(model, batch, input_scaler, target_scaler, criterion)\n",
    "            for k, m in val_metrics_epoch.items():\n",
    "                if k not in val_metrics: val_metrics[k] = []\n",
    "                val_metrics[k].append(m)\n",
    "\n",
    "        # Compute the mean on GPU  -> Faster for batch\n",
    "        train_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                         train_metrics.items()}\n",
    "        val_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                       val_metrics.items()}\n",
    "\n",
    "        log_epoch(train_metrics, val_metrics, epoch + 1)\n",
    "\n",
    "        negative_metrics = {'r2'}  # Set of metrics which are better when higher\n",
    "\n",
    "        for k, v in val_metrics.items():\n",
    "            f = 1 if k not in negative_metrics else -1\n",
    "            if f * best_val_metric[k]['value'] >= f * v:\n",
    "                best_val_metric[k] = {'model': deepcopy(model), 'value': v.item(), 'epoch': epoch + 1}\n",
    "\n",
    "        if (log_step < 0): continue\n",
    "        if (epoch % log_step == 0):\n",
    "            console_log(epoch + 1, train_metrics, val_metrics)\n",
    "\n",
    "    input, target, _, _, _ = train_dl.__iter__().__next__()\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(), target.cpu().detach().numpy())\n",
    "    for k, v in best_val_metric.items():\n",
    "        metric = v['value']\n",
    "        epoch = v['epoch']\n",
    "        log_model(f\"{k}_model\", v['model'], signature=signature, metadata={'metric': metric, 'epoch': epoch + 1})\n",
    "\n",
    "\n",
    "def trial_routine(run_name, train_routine, mlp_params, train_dataset, val_dataset, train_batch_size,\n",
    "                  val_batch_size, n_epoch, optimizer, lr, criterion, fold, log_step=10, log_params=None):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Model initialization\n",
    "        model = MLP(**mlp_params)\n",
    "\n",
    "        # Model information logging\n",
    "        capacity = sum(np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        if log_params is not None:\n",
    "            mlflow.log_params(log_params)\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params({\n",
    "            'n_hidden_layers': len(mlp_params['hidden_dims']),\n",
    "            'hidden_layers_size': mlp_params['hidden_dims'][0],\n",
    "            'capacity': capacity,\n",
    "            'n_epoch': n_epoch,\n",
    "            'val_batch_size': val_batch_size,\n",
    "            'train_batch_size': train_batch_size,\n",
    "            'train_size': train_dataset.__len__(),\n",
    "            'val_size': val_dataset.__len__(),\n",
    "            'k-fold': fold,\n",
    "            'optimizer': optimizer.__name__,\n",
    "            'learning_rate': f\"{lr:.1e}\",\n",
    "            'criterion': criterion.__name__,\n",
    "        })\n",
    "\n",
    "        # Run the training with the configuration\n",
    "        train_routine(model, train_dataset, val_dataset,\n",
    "                      train_batch_size, val_batch_size,\n",
    "                      n_epoch, optimizer(model.parameters(), lr=lr), criterion(), log_step=log_step)"
   ],
   "id": "9c3384af07696e93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot(results, configs, metric, labels, log=True, xlim=None, ylim=None):\n",
    "    cmap = mpl.colormaps['tab10']\n",
    "    c = cmap(np.linspace(0, 1, len(configs)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the data but collect the handles for the legend\n",
    "    config_handles = []\n",
    "    for i, conf in enumerate(configs):\n",
    "        # Store only the validation line handles for the legend\n",
    "        l = len(results[conf][f'train_{metric}'])\n",
    "        h = ax.plot(np.arange(l), results[conf][f'train_{metric}'], alpha=.5, ls='--', lw=1, c=c[i])[0]\n",
    "        h2 = ax.plot(np.arange(l), results[conf][f'val_{metric}'], ls='-', lw=1, c=c[i])[0]\n",
    "        config_handles.append(h2)\n",
    "\n",
    "    # Create custom handles for the line style legend\n",
    "    line_style_handles = [\n",
    "        Line2D([0], [0], color='black', lw=1, ls='--', alpha=0.5, label='Training'),\n",
    "        Line2D([0], [0], color='black', lw=1, ls='-', label='Validation'),\n",
    "        Line2D([0], [0], color='black', alpha=0, lw=1, ls='-')\n",
    "    ]\n",
    "\n",
    "    # Get the current position and size of the axis\n",
    "    box = ax.get_position()\n",
    "    # Reduce the width of the axis to make room for the legend\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Combine both sets of handles and labels\n",
    "    all_handles = line_style_handles + config_handles\n",
    "    all_labels = ['Training', 'Validation', ''] + labels\n",
    "\n",
    "    # Create a single legend with both line styles and configurations\n",
    "    plt.figlegend(all_handles, all_labels, loc='center left', bbox_to_anchor=(1, .5),\n",
    "                  title=\"Legend\")\n",
    "\n",
    "    ax.set_title(f\"Evolution of {metric} during training\")\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_ylabel(f\"{metric} [/]\")\n",
    "    ax.set_xlabel(\"epoch [/]\")\n",
    "\n",
    "    if xlim: ax.set_xlim(*xlim)\n",
    "    if ylim: ax.set_ylim(*ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Adjust right padding to make room for the legend\n",
    "    plt.show()"
   ],
   "id": "565adab5c6abd13b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning",
   "id": "4aecef68254ba0d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model capacity",
   "id": "b9f9cea82c9af10e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"model_capacity\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "n_layers_values = [2, 3, 4, 5]\n",
    "n_neurons_values = [65, 70, 80, 80, 100, 120]\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for n_layers in n_layers_values:\n",
    "        for n_neurons in n_neurons_values:\n",
    "            for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "                hidden_dims = [n_neurons for _ in range(n_layers)]\n",
    "                train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "                future = executor.submit(trial_routine, None, train,\n",
    "                                         {\n",
    "                                             'input_dim': 65,\n",
    "                                             'hidden_dims': hidden_dims,\n",
    "                                             'output_dim': 3,\n",
    "                                             'activation': \"relu\",\n",
    "                                             'activation_params': None,\n",
    "                                             'dropout': 0.0,\n",
    "                                             'batch_norm': False,\n",
    "                                             'layer_norm': False,\n",
    "                                             'normalization_params': None,\n",
    "                                             'output_activation': None,\n",
    "                                             'output_activation_params': None,\n",
    "                                         },\n",
    "                                         train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                         N_EPOCH,\n",
    "                                         torch.optim.Adam, LR, nn.MSELoss, kfold, log_step, {'loss': 'mse'})\n",
    "                futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "d6a5f3f09ec22e4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"model_capacity\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "layers_combinations = set()\n",
    "for n_layers in runs_df['params.n_hidden_layers'].unique():\n",
    "    for layer_size in runs_df['params.hidden_layers_size'].unique():\n",
    "        layers_combinations.add((n_layers, layer_size))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in layers_combinations}\n",
    "for n, size in layers_combinations:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse') &\n",
    "        (runs_df['params.n_hidden_layers'] == n) &\n",
    "        (runs_df['params.hidden_layers_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[(n, size)][metric_name].append(\n",
    "                [metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "551448082f7b2e78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "_configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = _configs\n",
    "configs = sorted(configs)\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [str([int(x) for x in cfg]) for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "ef0718394bb7c05c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_hidden_dims = [100 for _ in range(5)]",
   "id": "d750fd7bbb96921b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Activation function",
   "id": "e2b9284cb98ea052"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"activation_function\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "activation_values = ['relu', 'gelu', 'tanh', 'sigmoid',\n",
    "                     'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']\n",
    "activation_params_values = [None, None, None, None,\n",
    "                            {'negative_slope': 5e-1}, {'negative_slope': 1e-1}, {'negative_slope': 5e-2},\n",
    "                            {'negative_slope': 1e-2}]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for activation, activation_params in zip(activation_values, activation_params_values):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': activation,\n",
    "                                         'activation_params': activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, nn.MSELoss, kfold, log_step, {'loss': 'mse'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "24be6cc4958531d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"activation_function\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "activations_combinations = set()\n",
    "for m in runs_df['params.activation'].unique():\n",
    "    for n in runs_df[runs_df['params.activation'] == m]['params.activation_params'].unique():\n",
    "        activations_combinations.add((m, n))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in activations_combinations}\n",
    "for k in activations_combinations:\n",
    "    (act, params) = k\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse') &\n",
    "        (runs_df['params.activation'] == act) &\n",
    "        (runs_df['params.activation_params'] == params)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[k][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "3d8e83c5a937d53b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "configs = [x[1] for x in sorted([(np.min(v['val_mape']), k) for k, v in results.items()])]\n",
    "labels = [f\"[{cfg[0]}]\" if cfg[1] == 'None' else f\"[{cfg[0]}, {cfg[1]}]\" for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "88d13da54713d457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_activation = 'tanh'\n",
    "best_activation_params = None"
   ],
   "id": "95a2a9217944a819",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning rate",
   "id": "be18122400d486fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"learning_rate\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for LR in sorted(np.hstack([f * np.logspace(-5, -2, 4) for f in [1, 2.5, 5, 7.5]])):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': best_activation,\n",
    "                                         'activation_params': best_activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, nn.MSELoss, kfold, log_step, {'loss': 'mse'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "15c2de820ff3c2f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"learning_rate\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "learning_rates = set(runs_df['params.learning_rate'].unique())\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in learning_rates}\n",
    "for lr in learning_rates:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse') &\n",
    "        (runs_df['params.learning_rate'] == lr)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[lr][metric_name].append([metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "7df9663b0d9ccd77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{float(c):.1e}\" for c in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(0, 1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "eb1eb63d9313e8c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_lr = 1e-3",
   "id": "94669a3b8dc657d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "640e0a812ca241aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_lr_old = best_lr\n",
    "best_lr = 1e-3\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"training\")\n",
    "\n",
    "VAL_BATCH_SIZE = 8192\n",
    "N_EPOCH = 1_000\n",
    "log_step = -1\n",
    "\n",
    "sizes = [2 ** i for i in range(8, 15)]\n",
    "batch_size_values = [512 for _ in sizes]  # [int(min(np.power(2, np.floor(np.log2(n)) - 1), 512)) for n in sizes]\n",
    "dataset_path_values = [f\"data/dataset/pratt_truss_bridge/member_ea/train_{n}.hdf5\" for n in sizes]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, (dataset_path, TRAIN_BATCH_SIZE) in enumerate(zip(dataset_path_values, batch_size_values)):\n",
    "        size = sizes[i]\n",
    "        train_dataset = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "        validation_dataset = _validation_ds\n",
    "        future = executor.submit(trial_routine, None, train,\n",
    "                                 {\n",
    "                                     'input_dim': 65,\n",
    "                                     'hidden_dims': best_hidden_dims,\n",
    "                                     'output_dim': 3,\n",
    "                                     'activation': best_activation,\n",
    "                                     'activation_params': best_activation_params,\n",
    "                                     'dropout': 0.0,\n",
    "                                     'batch_norm': False,\n",
    "                                     'layer_norm': False,\n",
    "                                     'normalization_params': None,\n",
    "                                     'output_activation': None,\n",
    "                                     'output_activation_params': None\n",
    "                                 },\n",
    "                                 train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                 N_EPOCH,\n",
    "                                 torch.optim.Adam, best_lr, nn.MSELoss,\n",
    "                                 -1, log_step, {'loss': 'mse', 'noise': 0.})\n",
    "        futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "296d6c3cb88443b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "sizes = set()\n",
    "for size in runs_df['params.train_size'].unique():\n",
    "    sizes.add(size)\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in sizes}\n",
    "for size in sizes:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse') &\n",
    "        (runs_df['params.train_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[size][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "d9bc2a597bbfe067",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{int(size)}\" for size in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(-.2, 1.1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "7d0ec26766c51636",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Noise sensitivity",
   "id": "3108ba07b77a0b8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "results = []\n",
    "\n",
    "for f in np.linspace(0, .1, 6):\n",
    "    validation_ds = FixedPrattTrussDatasetThreeTargets(\n",
    "        \"data/dataset/pratt_truss_bridge/member_ea/validation_8192.hdf5\",\n",
    "        f_noise_length=None,\n",
    "        f_noise_loads=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_strain=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_displacement=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "    )\n",
    "\n",
    "    dl = DataLoader(validation_ds, batch_size=8192)\n",
    "\n",
    "    for i in range(len(runs_df[['artifact_uri', 'params.train_size']])):\n",
    "        artifact_uri = runs_df.iloc[i]['artifact_uri']\n",
    "        size = runs_df.iloc[i]['params.train_size']\n",
    "\n",
    "        uri = f\"{artifact_uri}/input_scaler/\"\n",
    "        input_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/target_scaler/\"\n",
    "        target_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/mape_model/\"\n",
    "        model = load_model(uri)\n",
    "\n",
    "        for batch in dl:\n",
    "            metrics = validation(model, batch, input_scaler, target_scaler, F.mse_loss)\n",
    "        results.append((size, f, metrics))"
   ],
   "id": "f3a825949f5030c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"noise_sensitivity\")\n",
    "\n",
    "df = pd.DataFrame([[results[i][0], results[i][1],\n",
    "                    results[i][2]['r2'].item(),\n",
    "                    results[i][2]['mape'].item(),\n",
    "                    results[i][2]['rmse_MN'].item(),\n",
    "                    results[i][2]['loss']]\n",
    "                   for i in range(len(results))], columns=['train_size', 'noise', 'r2', 'mape', 'rmse_MN', 'loss'])\n",
    "df.sort_values(by=['train_size', 'noise'], axis=0, ignore_index=True, inplace=True)\n",
    "\n",
    "for size in df.train_size.unique():\n",
    "    with mlflow.start_run():\n",
    "        df_2 = df[df['train_size'] == size]\n",
    "        # Model information logging\n",
    "        mlflow.log_params({\n",
    "            'train_size': size,\n",
    "            'loss': 'mse'\n",
    "        })\n",
    "        for i in range(len(df_2)):\n",
    "            mlflow.log_metrics(\n",
    "                dict(df_2.iloc[i][1:]),\n",
    "                step=i\n",
    "            )"
   ],
   "id": "c87779b42494d0e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PINN Only",
   "id": "c0b3550ff36ce709"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:51:44.115221Z",
     "start_time": "2025-05-09T21:51:44.100507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def u_from_x(x, n_panels=8):\n",
    "    batch_size = len(x)\n",
    "    u = torch.zeros((batch_size, 4 * n_panels), device=x.device)\n",
    "    u[:, 2:2 * n_panels + 1] = x[:, :2 * (n_panels - 1) + 1]\n",
    "    u[:, 2 * (n_panels + 1):] = x[:, 2 * (n_panels - 1) + 1:4 * n_panels - 3]\n",
    "    return u.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def q_from_x_q(x, q, n_panels=8):\n",
    "    q = q.squeeze(-1)\n",
    "    q[:, np.arange(3, 2 * n_panels, 2)] = x[:, 4 * n_panels - 3: 5 * n_panels - 4]\n",
    "\n",
    "    return q.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def train_step(model, batch, input_scaler, target_scaler, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    input, target, _, u, q = batch\n",
    "    input, target = input.to(device), target.to(device)\n",
    "    u, q = u.to(device), q.to(device)\n",
    "    q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "    z_input = input_scaler.transform(input)\n",
    "    z_target = target_scaler.transform(target)\n",
    "\n",
    "    z_target_pred = model(z_input)\n",
    "    target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "    k_pred = pratt_stiffness_matrix(7.5, 7.5, get_total_EA_vector(target_pred)).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(k_pred * 1e-6,\n",
    "                     u_from_x(input, 8) * 1e3,\n",
    "                     q_from_x_q(input, q, 8) * 1e-3)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validation(model, batch, input_scaler, target_scaler, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input, target, _, u, q = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        u, q = u.to(device), q.to(device)\n",
    "        q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "        z_input = input_scaler.transform(input)\n",
    "        z_target = target_scaler.transform(target)\n",
    "\n",
    "        z_target_pred = model(z_input)\n",
    "        target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "        k_pred = pratt_stiffness_matrix(7.5, 7.5, get_total_EA_vector(target_pred)).to(device)\n",
    "\n",
    "        loss = criterion(k_pred * 1e-6,\n",
    "                         u_from_x(input, 8) * 1e3,\n",
    "                         q_from_x_q(input, q, 8) * 1e-3)\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(model, target_pred, z_target_pred, target, z_target):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        r2 = R.r2_score(z_target_pred, z_target)\n",
    "        if r2.isinf():  # Switch to 64 bits in case of overflow\n",
    "            r2 = R.r2_score(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64))\n",
    "        mape = R.mean_absolute_percentage_error(target_pred, target)\n",
    "        rmse = R.mean_squared_error(target_pred * 1e-6, target * 1e-6, squared=False)\n",
    "        if rmse.isinf():  # Switch to 64 bits in case of overflow\n",
    "            rmse = R.mean_squared_error(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64),\n",
    "                                        squared=False)\n",
    "\n",
    "    return {'r2': r2, 'mape': mape, 'rmse_MN': rmse}\n",
    "\n",
    "\n",
    "def log_epoch(train_metrics, val_metrics, epoch):\n",
    "    metrics = dict()\n",
    "    metrics.update({f'train_{k}': v for k, v in train_metrics.items()})\n",
    "    metrics.update({f'val_{k}': v for k, v in val_metrics.items()})\n",
    "\n",
    "    mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "\n",
    "def log_model(name, model, signature, metadata=None):\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=name,\n",
    "        signature=signature,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "\n",
    "def console_log(epoch, train_metrics, val_metrics):\n",
    "    print(f\">> Epoch {epoch + 1:4d}\", end='  ')\n",
    "    print(f\"TRAIN\", end='   ')\n",
    "    metric_names = {k for k in train_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = train_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "\n",
    "    print(\"  ||  \", end='')\n",
    "    print(f\"VALIDATION\", end='   ')\n",
    "    metric_names = {k for k in val_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss'] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = val_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "    print()\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion,\n",
    "          log_step=10):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    train_dl = DataLoader(train_dataset, train_batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, val_batch_size, shuffle=False)\n",
    "\n",
    "    input_scaler = StandardScaler(train_dataset[0][0].__len__()).to(device)\n",
    "    target_scaler = StandardScaler(train_dataset[0][1].__len__()).to(device)\n",
    "\n",
    "    # Train the scaler\n",
    "    input, target = None, None\n",
    "    for batch in train_dl:\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        input_scaler.partial_fit(input)\n",
    "        target_scaler.partial_fit(target)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(),\n",
    "                                              input_scaler.transform(input).cpu().detach().numpy())\n",
    "    log_model('input_scaler', input_scaler, signature=signature)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(target.cpu().detach().numpy(),\n",
    "                                              target_scaler.transform(target).cpu().detach().numpy())\n",
    "    log_model('target_scaler', target_scaler, signature=signature)\n",
    "\n",
    "    best_val_metric = {\n",
    "        'mape': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'rmse_MN': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'r2': {model: None, 'value': -np.inf, 'epoch': -1}\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_metrics = {}\n",
    "        val_metrics = {}\n",
    "        for batch in train_dl:\n",
    "            train_metrics_epoch = train_step(model, batch, input_scaler, target_scaler, optimizer, criterion)\n",
    "            for k, m in train_metrics_epoch.items():\n",
    "                if k not in train_metrics: train_metrics[k] = []\n",
    "                train_metrics[k].append(m)\n",
    "\n",
    "        for batch in val_dl:\n",
    "            val_metrics_epoch = validation(model, batch, input_scaler, target_scaler, criterion)\n",
    "            for k, m in val_metrics_epoch.items():\n",
    "                if k not in val_metrics: val_metrics[k] = []\n",
    "                val_metrics[k].append(m)\n",
    "\n",
    "        # Compute the mean on GPU  -> Faster for batch\n",
    "        train_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                         train_metrics.items()}\n",
    "        val_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                       val_metrics.items()}\n",
    "\n",
    "        log_epoch(train_metrics, val_metrics, epoch + 1)\n",
    "\n",
    "        negative_metrics = {'r2'}  # Set of metrics which are better when higher\n",
    "\n",
    "        for k, v in val_metrics.items():\n",
    "            f = 1 if k not in negative_metrics else -1\n",
    "            if f * best_val_metric[k]['value'] >= f * v:\n",
    "                best_val_metric[k] = {'model': deepcopy(model), 'value': v.item(), 'epoch': epoch + 1}\n",
    "\n",
    "        if (log_step < 0): continue\n",
    "        if (epoch % log_step == 0):\n",
    "            console_log(epoch + 1, train_metrics, val_metrics)\n",
    "\n",
    "    input, target, _, _, _ = train_dl.__iter__().__next__()\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(), target.cpu().detach().numpy())\n",
    "    for k, v in best_val_metric.items():\n",
    "        metric = v['value']\n",
    "        epoch = v['epoch']\n",
    "        log_model(f\"{k}_model\", v['model'], signature=signature, metadata={'metric': metric, 'epoch': epoch + 1})\n",
    "\n",
    "\n",
    "def trial_routine(run_name, train_routine, mlp_params, train_dataset, val_dataset, train_batch_size,\n",
    "                  val_batch_size, n_epoch, optimizer, lr, criterion, fold, log_step=10, log_params=None):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Model initialization\n",
    "        model = MLP(**mlp_params)\n",
    "\n",
    "        # Model information logging\n",
    "        capacity = sum(np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        if log_params is not None:\n",
    "            mlflow.log_params(log_params)\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params({\n",
    "            'n_hidden_layers': len(mlp_params['hidden_dims']),\n",
    "            'hidden_layers_size': mlp_params['hidden_dims'][0],\n",
    "            'capacity': capacity,\n",
    "            'n_epoch': n_epoch,\n",
    "            'val_batch_size': val_batch_size,\n",
    "            'train_batch_size': train_batch_size,\n",
    "            'train_size': train_dataset.__len__(),\n",
    "            'val_size': val_dataset.__len__(),\n",
    "            'k-fold': fold,\n",
    "            'optimizer': optimizer.__name__,\n",
    "            'learning_rate': lr,\n",
    "            'criterion': criterion.__name__,\n",
    "        })\n",
    "\n",
    "        # Run the training with the configuration\n",
    "        train_routine(model, train_dataset, val_dataset,\n",
    "                      train_batch_size, val_batch_size,\n",
    "                      n_epoch, optimizer(model.parameters(), lr=lr), criterion(), log_step=log_step)"
   ],
   "id": "58683be2635ab2d4",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:51:44.150587Z",
     "start_time": "2025-05-09T21:51:44.146844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot(results, configs, metric, labels, log=True, xlim=None, ylim=None):\n",
    "    cmap = mpl.colormaps['tab10']\n",
    "    c = cmap(np.linspace(0, 1, len(configs)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the data but collect the handles for the legend\n",
    "    config_handles = []\n",
    "    for i, conf in enumerate(configs):\n",
    "        # Store only the validation line handles for the legend\n",
    "        l = len(results[conf][f'train_{metric}'])\n",
    "        h = ax.plot(np.arange(l), results[conf][f'train_{metric}'], alpha=.5, ls='--', lw=1, c=c[i])[0]\n",
    "        h2 = ax.plot(np.arange(l), results[conf][f'val_{metric}'], ls='-', lw=1, c=c[i])[0]\n",
    "        config_handles.append(h2)\n",
    "\n",
    "    # Create custom handles for the line style legend\n",
    "    line_style_handles = [\n",
    "        Line2D([0], [0], color='black', lw=1, ls='--', alpha=0.5, label='Training'),\n",
    "        Line2D([0], [0], color='black', lw=1, ls='-', label='Validation'),\n",
    "        Line2D([0], [0], color='black', alpha=0, lw=1, ls='-')\n",
    "    ]\n",
    "\n",
    "    # Get the current position and size of the axis\n",
    "    box = ax.get_position()\n",
    "    # Reduce the width of the axis to make room for the legend\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Combine both sets of handles and labels\n",
    "    all_handles = line_style_handles + config_handles\n",
    "    all_labels = ['Training', 'Validation', ''] + labels\n",
    "\n",
    "    # Create a single legend with both line styles and configurations\n",
    "    plt.figlegend(all_handles, all_labels, loc='center left', bbox_to_anchor=(1, .5),\n",
    "                  title=\"Legend\")\n",
    "\n",
    "    ax.set_title(f\"Evolution of {metric} during training\")\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_ylabel(f\"{metric} [/]\")\n",
    "    ax.set_xlabel(\"epoch [/]\")\n",
    "\n",
    "    if xlim: ax.set_xlim(*xlim)\n",
    "    if ylim: ax.set_ylim(*ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Adjust right padding to make room for the legend\n",
    "    plt.show()"
   ],
   "id": "4656b11cc9d9bd4b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning",
   "id": "840cb2e7a63d5d3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model capacity",
   "id": "c27e4e25d5482e1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:51:44.092342Z",
     "start_time": "2025-05-09T21:44:33.318823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"model_capacity\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 400#200\n",
    "LR = 5e-3\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "n_layers_values = [5]#[2, 3, 4, 5]\n",
    "n_neurons_values = [65]#, 70, 80, 80, 100, 120]\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for n_layers in n_layers_values:\n",
    "        for n_neurons in n_neurons_values:\n",
    "            for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "                hidden_dims = [n_neurons for _ in range(n_layers)]\n",
    "                train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "                future = executor.submit(trial_routine, None, train,\n",
    "                                         {\n",
    "                                             'input_dim': 65,\n",
    "                                             'hidden_dims': hidden_dims,\n",
    "                                             'output_dim': 3,\n",
    "                                             'activation': \"tanh\",\n",
    "                                             'activation_params': None,\n",
    "                                             'dropout': 0.0,\n",
    "                                             'batch_norm': False,\n",
    "                                             'layer_norm': False,\n",
    "                                             'normalization_params': None,\n",
    "                                             'output_activation': None,\n",
    "                                             'output_activation_params': None,\n",
    "                                         },\n",
    "                                         train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                         N_EPOCH,\n",
    "                                         torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': 'pinn'})\n",
    "                futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "e78034f8196aa67e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run glamorous-seal-922 at: http://127.0.0.1:5010/#/experiments/163656726481012533/runs/e8cea83a61b04faf86cd543a5dfa976b\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/163656726481012533\n",
      "🏃 View run stately-kite-773 at: http://127.0.0.1:5010/#/experiments/163656726481012533/runs/ff92a1a44b9a40d599f72c8be2c2df13\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/163656726481012533\n",
      "🏃 View run efficient-cod-91 at: http://127.0.0.1:5010/#/experiments/163656726481012533/runs/44437e7ccff7482791869bd51afa9824\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/163656726481012533\n",
      "🏃 View run overjoyed-croc-985 at: http://127.0.0.1:5010/#/experiments/163656726481012533/runs/932889af15e34f689f2082b5acd78212\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/163656726481012533\n",
      "🏃 View run enthused-koi-622 at: http://127.0.0.1:5010/#/experiments/163656726481012533/runs/d89f708e541344fbafcd481d6bdd55cc\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/163656726481012533\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"model_capacity\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "layers_combinations = set()\n",
    "for n_layers in runs_df['params.n_hidden_layers'].unique():\n",
    "    for layer_size in runs_df['params.hidden_layers_size'].unique():\n",
    "        layers_combinations.add((n_layers, layer_size))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in layers_combinations}\n",
    "for n, size in layers_combinations:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'pinn') &\n",
    "        (runs_df['params.n_hidden_layers'] == n) &\n",
    "        (runs_df['params.hidden_layers_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[(n, size)][metric_name].append(\n",
    "                [metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "ebd853d3310e876f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "_configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = _configs\n",
    "configs = sorted(configs)\n",
    "configs = [x[1] for x in configs][:5]\n",
    "\n",
    "labels = [str([int(x) for x in cfg]) for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "960c037489f6c16f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_hidden_dims = [65 for _ in range(5)]",
   "id": "7120ddf5c78cebae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Activation function",
   "id": "484cb8d012a709e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"activation_function\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "activation_values = ['relu', 'gelu', 'tanh', 'sigmoid',\n",
    "                     'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']\n",
    "activation_params_values = [None, None, None, None,\n",
    "                            {'negative_slope': 5e-1}, {'negative_slope': 1e-1}, {'negative_slope': 5e-2},\n",
    "                            {'negative_slope': 1e-2}]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for activation, activation_params in zip(activation_values, activation_params_values):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': activation,\n",
    "                                         'activation_params': activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': 'pinn'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "37e57cfd853b166a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"activation_function\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "activations_combinations = set()\n",
    "for m in runs_df['params.activation'].unique():\n",
    "    for n in runs_df[runs_df['params.activation'] == m]['params.activation_params'].unique():\n",
    "        activations_combinations.add((m, n))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in activations_combinations}\n",
    "for k in activations_combinations:\n",
    "    (act, params) = k\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'pinn') &\n",
    "        (runs_df['params.activation'] == act) &\n",
    "        (runs_df['params.activation_params'] == params)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[k][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "584079e00ea65421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "configs = [x[1] for x in sorted([(np.min(v['val_mape']), k) for k, v in results.items()])]\n",
    "labels = [f\"[{cfg[0]}]\" if cfg[1] == 'None' else f\"[{cfg[0]}, {cfg[1]}]\" for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "e7afd208870ef0a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_activation = 'leaky_relu'\n",
    "best_activation_params = {'negative_slope': 1e-2}"
   ],
   "id": "db29b9a2ef600776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning rate",
   "id": "5f98ea0403d41662"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"learning_rate\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for LR in sorted(np.hstack([f * np.logspace(-5, -2, 4) for f in [1, 2.5, 5, 7.5]])):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': best_activation,\n",
    "                                         'activation_params': best_activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, StiffnessToLoadLoss, kfold, log_step, {'loss': 'pinn'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "d9c549483f3e9a7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"learning_rate\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "learning_rates = set(runs_df['params.learning_rate'].unique())\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in learning_rates}\n",
    "for lr in learning_rates:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'pinn') &\n",
    "        (runs_df['params.learning_rate'] == lr)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[lr][metric_name].append([metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "f0020d6096d9a915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs][:4]\n",
    "\n",
    "\"\"\"configs = [\n",
    " '7.5e-04',\n",
    " '5.0e-04',\n",
    " '2.5e-04',\n",
    " '1.0e-04',]\n",
    "\"\"\"\n",
    "labels = [f\"{float(c):.1e}\" for c in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(0, 1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "d20a9cce2b86d0b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_lr = 5e-4",
   "id": "ea25ab88a74692b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "b65cb7bc428ade8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_lr_old = best_lr\n",
    "best_lr = 5e-4\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"training\")\n",
    "\n",
    "VAL_BATCH_SIZE = 8192\n",
    "N_EPOCH = 1_000\n",
    "log_step = -1\n",
    "\n",
    "sizes = [2 ** i for i in range(8, 15)]\n",
    "batch_size_values = [512 for _ in sizes]  # [int(min(np.power(2, np.floor(np.log2(n)) - 1), 512)) for n in sizes]\n",
    "dataset_path_values = [f\"data/dataset/pratt_truss_bridge/member_ea/train_{n}.hdf5\" for n in sizes]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, (dataset_path, TRAIN_BATCH_SIZE) in enumerate(zip(dataset_path_values, batch_size_values)):\n",
    "        size = sizes[i]\n",
    "        train_dataset = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "        validation_dataset = _validation_ds\n",
    "        future = executor.submit(trial_routine, None, train,\n",
    "                                 {\n",
    "                                     'input_dim': 65,\n",
    "                                     'hidden_dims': best_hidden_dims,\n",
    "                                     'output_dim': 3,\n",
    "                                     'activation': best_activation,\n",
    "                                     'activation_params': best_activation_params,\n",
    "                                     'dropout': 0.0,\n",
    "                                     'batch_norm': False,\n",
    "                                     'layer_norm': False,\n",
    "                                     'normalization_params': None,\n",
    "                                     'output_activation': None,\n",
    "                                     'output_activation_params': None\n",
    "                                 },\n",
    "                                 train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                 N_EPOCH,\n",
    "                                 torch.optim.Adam, best_lr, StiffnessToLoadLoss,\n",
    "                                 -1, log_step, {'loss': 'pinn', 'noise': 0.})\n",
    "        futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "ebc5e239f2ea67db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "sizes = set()\n",
    "for size in runs_df['params.train_size'].unique():\n",
    "    sizes.add(size)\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in sizes}\n",
    "for size in sizes:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'pinn') &\n",
    "        (runs_df['params.train_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[size][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "e8e5e0a5588e7c07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{int(size)}\" for size in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(-.2, 1.1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "cfee1b1fc6929afc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Noise sensitivity",
   "id": "97ef5d4a3a218f60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "results = []\n",
    "\n",
    "for f in np.linspace(0, .1, 6):\n",
    "    validation_ds = FixedPrattTrussDatasetThreeTargets(\n",
    "        \"data/dataset/pratt_truss_bridge/member_ea/validation_8192.hdf5\",\n",
    "        f_noise_length=None,\n",
    "        f_noise_loads=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_strain=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_displacement=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "    )\n",
    "\n",
    "    dl = DataLoader(validation_ds, batch_size=8192)\n",
    "\n",
    "    for i in range(len(runs_df[['artifact_uri', 'params.train_size']])):\n",
    "        artifact_uri = runs_df.iloc[i]['artifact_uri']\n",
    "        size = runs_df.iloc[i]['params.train_size']\n",
    "\n",
    "        uri = f\"{artifact_uri}/input_scaler/\"\n",
    "        input_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/target_scaler/\"\n",
    "        target_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/mape_model/\"\n",
    "        model = load_model(uri)\n",
    "\n",
    "        for batch in dl:\n",
    "            metrics = validation(model, batch, input_scaler, target_scaler, StiffnessToLoadLoss())\n",
    "        results.append((size, f, metrics))"
   ],
   "id": "e00e83dc62b0decb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"noise_sensitivity\")\n",
    "\n",
    "df = pd.DataFrame([[results[i][0], results[i][1],\n",
    "                    results[i][2]['r2'].item(),\n",
    "                    results[i][2]['mape'].item(),\n",
    "                    results[i][2]['rmse_MN'].item(),\n",
    "                    results[i][2]['loss']]\n",
    "                   for i in range(len(results))], columns=['train_size', 'noise', 'r2', 'mape', 'rmse_MN', 'loss'])\n",
    "df.sort_values(by=['train_size', 'noise'], axis=0, ignore_index=True, inplace=True)\n",
    "\n",
    "for size in df.train_size.unique():\n",
    "    with mlflow.start_run():\n",
    "        df_2 = df[df['train_size'] == size]\n",
    "        # Model information logging\n",
    "        mlflow.log_params({\n",
    "            'train_size': size,\n",
    "            'loss': 'mse'\n",
    "        })\n",
    "        for i in range(len(df_2)):\n",
    "            mlflow.log_metrics(\n",
    "                dict(df_2.iloc[i][1:]),\n",
    "                step=i\n",
    "            )"
   ],
   "id": "1a6ad3fbfb262585",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MSE + PINN",
   "id": "16c4a2b3e54f10e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:57:37.802155Z",
     "start_time": "2025-05-09T21:57:37.788832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def u_from_x(x, n_panels=8):\n",
    "    batch_size = len(x)\n",
    "    u = torch.zeros((batch_size, 4 * n_panels), device=x.device)\n",
    "    u[:, 2:2 * n_panels + 1] = x[:, :2 * (n_panels - 1) + 1]\n",
    "    u[:, 2 * (n_panels + 1):] = x[:, 2 * (n_panels - 1) + 1:4 * n_panels - 3]\n",
    "    return u.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def q_from_x_q(x, q, n_panels=8):\n",
    "    q = q.squeeze(-1)\n",
    "    q[:, np.arange(3, 2 * n_panels, 2)] = x[:, 4 * n_panels - 3: 5 * n_panels - 4]\n",
    "\n",
    "    return q.unsqueeze(-1)\n",
    "\n",
    "\n",
    "def train_step(model, batch, input_scaler, target_scaler, optimizer, criterion_data, criterion_phys, f_criterion_phys):\n",
    "    model.train()\n",
    "\n",
    "    input, target, _, u, q = batch\n",
    "    input, target = input.to(device), target.to(device)\n",
    "    u, q = u.to(device), q.to(device)\n",
    "    q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "    z_input = input_scaler.transform(input)\n",
    "    z_target = target_scaler.transform(target)\n",
    "\n",
    "    z_target_pred = model(z_input)\n",
    "    target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "    k_pred = pratt_stiffness_matrix(7.5, 7.5, get_total_EA_vector(target_pred)).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_data = criterion_data(z_target_pred, z_target)\n",
    "    loss_phys = criterion_phys(k_pred * 1e-6,\n",
    "                               u_from_x(input, 8) * 1e3,\n",
    "                               q_from_x_q(input, q, 8) * 1e-3)\n",
    "\n",
    "    loss = loss_data + loss_phys * f_criterion_phys\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss_data'] = loss_data.item()\n",
    "    metrics['loss_phys'] = loss_phys.item()\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validation(model, batch, input_scaler, target_scaler, criterion_data, criterion_phys, f_criterion_phys):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input, target, _, u, q = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        u, q = u.to(device), q.to(device)\n",
    "        q[:, [0, 1, 17], :] = 0.\n",
    "\n",
    "        z_input = input_scaler.transform(input)\n",
    "        z_target = target_scaler.transform(target)\n",
    "\n",
    "        z_target_pred = model(z_input)\n",
    "        target_pred = target_scaler.inverse_transform(z_target_pred)\n",
    "\n",
    "        k_pred = pratt_stiffness_matrix(7.5, 7.5, get_total_EA_vector(target_pred)).to(device)\n",
    "\n",
    "        loss_data = criterion_data(z_target_pred, z_target)\n",
    "        loss_phys = criterion_phys(k_pred * 1e-6,\n",
    "                                   u_from_x(input, 8) * 1e3,\n",
    "                                   q_from_x_q(input, q, 8) * 1e-3)\n",
    "        loss = loss_data + loss_phys * f_criterion_phys\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss_data'] = loss_data.item()\n",
    "    metrics['loss_phys'] = loss_phys.item()\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(model, target_pred, z_target_pred, target, z_target):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        r2 = R.r2_score(z_target_pred, z_target)\n",
    "        if r2.isinf():  # Switch to 64 bits in case of overflow\n",
    "            r2 = R.r2_score(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64))\n",
    "        mape = R.mean_absolute_percentage_error(target_pred, target)\n",
    "        rmse = R.mean_squared_error(target_pred * 1e-6, target * 1e-6, squared=False)\n",
    "        if rmse.isinf():  # Switch to 64 bits in case of overflow\n",
    "            rmse = R.mean_squared_error(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64),\n",
    "                                        squared=False)\n",
    "\n",
    "    return {'r2': r2, 'mape': mape, 'rmse_MN': rmse}\n",
    "\n",
    "\n",
    "def log_epoch(train_metrics, val_metrics, epoch):\n",
    "    metrics = dict()\n",
    "    metrics.update({f'train_{k}': v for k, v in train_metrics.items()})\n",
    "    metrics.update({f'val_{k}': v for k, v in val_metrics.items()})\n",
    "\n",
    "    mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "\n",
    "def log_model(name, model, signature, metadata=None):\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=name,\n",
    "        signature=signature,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "\n",
    "def console_log(epoch, train_metrics, val_metrics):\n",
    "    print(f\">> Epoch {epoch + 1:4d}\", end='  ')\n",
    "    print(f\"TRAIN\", end='   ')\n",
    "    metric_names = {k for k in train_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss', 'loss_data', \"loss_phys\"] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = train_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "\n",
    "    print(\"  ||  \", end='')\n",
    "    print(f\"VALIDATION\", end='   ')\n",
    "    metric_names = {k for k in val_metrics.keys() if k != 'loss'}\n",
    "    metric_names = ['loss', 'loss_data', \"loss_phys\"] + sorted(metric_names)\n",
    "    for k in metric_names:\n",
    "        v = val_metrics[k]\n",
    "        print(f\"{k}: {v: 1.4f}\", end='   ')\n",
    "    print()\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer,\n",
    "          criterion_data, criterion_phys, f_criterion_phys, log_step=10):\n",
    "    model = model.to(device)\n",
    "    criterion_phys = criterion_phys.to(device)\n",
    "    criterion_data = criterion_data.to(device)\n",
    "    train_dl = DataLoader(train_dataset, train_batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, val_batch_size, shuffle=False)\n",
    "\n",
    "    input_scaler = StandardScaler(train_dataset[0][0].__len__()).to(device)\n",
    "    target_scaler = StandardScaler(train_dataset[0][1].__len__()).to(device)\n",
    "\n",
    "    # Train the scaler\n",
    "    input, target = None, None\n",
    "    for batch in train_dl:\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        input_scaler.partial_fit(input)\n",
    "        target_scaler.partial_fit(target)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(),\n",
    "                                              input_scaler.transform(input).cpu().detach().numpy())\n",
    "    log_model('input_scaler', input_scaler, signature=signature)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(target.cpu().detach().numpy(),\n",
    "                                              target_scaler.transform(target).cpu().detach().numpy())\n",
    "    log_model('target_scaler', target_scaler, signature=signature)\n",
    "\n",
    "    best_val_metric = {\n",
    "        'mape': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'rmse_MN': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss_phys': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss_data': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'r2': {model: None, 'value': -np.inf, 'epoch': -1}\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_metrics = {}\n",
    "        val_metrics = {}\n",
    "        for batch in train_dl:\n",
    "            train_metrics_epoch = train_step(model, batch, input_scaler, target_scaler, optimizer,\n",
    "                                             criterion_data, criterion_phys, f_criterion_phys)\n",
    "            for k, m in train_metrics_epoch.items():\n",
    "                if k not in train_metrics: train_metrics[k] = []\n",
    "                train_metrics[k].append(m)\n",
    "\n",
    "        for batch in val_dl:\n",
    "            val_metrics_epoch = validation(model, batch, input_scaler, target_scaler,\n",
    "                                           criterion_data, criterion_phys, f_criterion_phys)\n",
    "            for k, m in val_metrics_epoch.items():\n",
    "                if k not in val_metrics: val_metrics[k] = []\n",
    "                val_metrics[k].append(m)\n",
    "\n",
    "        # Compute the mean on GPU  -> Faster for batch\n",
    "        train_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                         train_metrics.items()}\n",
    "        val_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                       val_metrics.items()}\n",
    "\n",
    "        log_epoch(train_metrics, val_metrics, epoch)\n",
    "\n",
    "        negative_metrics = {'r2'}  # Set of metrics which are better when higher\n",
    "\n",
    "        for k, v in val_metrics.items():\n",
    "            f = 1 if k not in negative_metrics else -1\n",
    "            if f * best_val_metric[k]['value'] >= f * v:\n",
    "                best_val_metric[k] = {'model': deepcopy(model), 'value': v.item(), 'epoch': epoch}\n",
    "\n",
    "        if (log_step < 0): continue\n",
    "        if (epoch % log_step == 0):\n",
    "            console_log(epoch, train_metrics, val_metrics)\n",
    "\n",
    "    input, target, _, _, _ = train_dl.__iter__().__next__()\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(), target.cpu().detach().numpy())\n",
    "    for k, v in best_val_metric.items():\n",
    "        metric = v['value']\n",
    "        epoch = v['epoch']\n",
    "        log_model(f\"{k}_model\", v['model'], signature=signature, metadata={'metric': metric, 'epoch': epoch})\n",
    "\n",
    "\n",
    "def trial_routine(run_name, train_routine, mlp_params, train_dataset, val_dataset, train_batch_size,\n",
    "                  val_batch_size, n_epoch, optimizer, lr, criterion_data, criterion_phys, f_criterion_phys,\n",
    "                  fold, log_step=10, log_params=None):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Model initialization\n",
    "        model = MLP(**mlp_params)\n",
    "\n",
    "        # Model information logging\n",
    "        capacity = sum(np.prod(p.size()) for p in filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        if log_params is not None:\n",
    "            mlflow.log_params(log_params)\n",
    "        mlflow.log_params(mlp_params)\n",
    "        mlflow.log_params({\n",
    "            'n_hidden_layers': len(mlp_params['hidden_dims']),\n",
    "            'hidden_layers_size': mlp_params['hidden_dims'][0],\n",
    "            'capacity': capacity,\n",
    "            'n_epoch': n_epoch,\n",
    "            'val_batch_size': val_batch_size,\n",
    "            'train_batch_size': train_batch_size,\n",
    "            'train_size': train_dataset.__len__(),\n",
    "            'val_size': val_dataset.__len__(),\n",
    "            'k-fold': fold,\n",
    "            'optimizer': optimizer.__name__,\n",
    "            'learning_rate': lr,\n",
    "            'criterion_data': criterion_data.__name__,\n",
    "            'criterion_phys': criterion_phys.__name__,\n",
    "            'pinn_factor': f_criterion_phys\n",
    "        })\n",
    "\n",
    "        # Run the training with the configuration\n",
    "        train_routine(model, train_dataset, val_dataset,\n",
    "                      train_batch_size, val_batch_size,\n",
    "                      n_epoch, optimizer(model.parameters(), lr=lr),\n",
    "                      criterion_data(), criterion_phys(), f_criterion_phys,\n",
    "                      log_step=log_step)"
   ],
   "id": "a3489fa580a414bd",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T21:57:38.880108Z",
     "start_time": "2025-05-09T21:57:38.876848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot(results, configs, metric, labels, log=True, xlim=None, ylim=None):\n",
    "    cmap = mpl.colormaps['tab10']\n",
    "    c = cmap(np.linspace(0, 1, len(configs)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the data but collect the handles for the legend\n",
    "    config_handles = []\n",
    "    for i, conf in enumerate(configs):\n",
    "        # Store only the validation line handles for the legend\n",
    "        l = len(results[conf][f'train_{metric}'])\n",
    "        h = ax.plot(np.arange(l), results[conf][f'train_{metric}'], alpha=.5, ls='--', lw=1, c=c[i])[0]\n",
    "        h2 = ax.plot(np.arange(l), results[conf][f'val_{metric}'], ls='-', lw=1, c=c[i])[0]\n",
    "        config_handles.append(h2)\n",
    "\n",
    "    # Create custom handles for the line style legend\n",
    "    line_style_handles = [\n",
    "        Line2D([0], [0], color='black', lw=1, ls='--', alpha=0.5, label='Training'),\n",
    "        Line2D([0], [0], color='black', lw=1, ls='-', label='Validation'),\n",
    "        Line2D([0], [0], color='black', alpha=0, lw=1, ls='-')\n",
    "    ]\n",
    "\n",
    "    # Get the current position and size of the axis\n",
    "    box = ax.get_position()\n",
    "    # Reduce the width of the axis to make room for the legend\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Combine both sets of handles and labels\n",
    "    all_handles = line_style_handles + config_handles\n",
    "    all_labels = ['Training', 'Validation', ''] + labels\n",
    "\n",
    "    # Create a single legend with both line styles and configurations\n",
    "    plt.figlegend(all_handles, all_labels, loc='center left', bbox_to_anchor=(1, .5),\n",
    "                  title=\"Legend\")\n",
    "\n",
    "    ax.set_title(f\"Evolution of {metric} during training\")\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_ylabel(f\"{metric} [/]\")\n",
    "    ax.set_xlabel(\"epoch [/]\")\n",
    "\n",
    "    if xlim: ax.set_xlim(*xlim)\n",
    "    if ylim: ax.set_ylim(*ylim)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Adjust right padding to make room for the legend\n",
    "    plt.show()"
   ],
   "id": "569667c615039eaa",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter tuning",
   "id": "9eab9a3d4dd8e37e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss factor",
   "id": "9b43875e95cb62ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T22:04:50.604260Z",
     "start_time": "2025-05-09T21:57:40.836618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"pinn_loss_factor\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "factor_values = np.logspace(-6, -5, 2)  #np.logspace(-4, 1, 6)\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for f_pinn in factor_values:\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': [60 for _ in range(4)],\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': \"relu\",\n",
    "                                         'activation_params': None,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, nn.MSELoss, StiffnessToLoadLoss, f_pinn,\n",
    "                                     kfold, log_step, {'loss': 'mse + pinn'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "6113783534b09878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-tern-339 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/64fd8ad20736437d946b4296adf239fc\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run treasured-wren-943 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/e84cc8de8e17479b83a3bf740a1874a1\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run exultant-snipe-734 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/26fb9cca21744d29bfa8ec750219a85b\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run lyrical-colt-727 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/95dd17a681824f639a3ce8a82331d0e0\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run resilient-colt-740 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/5c3aae962268485d864f763bb721ad6f\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run clean-tern-742 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/488cf49b17d4457a8ed93fca9f025e13\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run stylish-mare-0 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/a83e8159444b42919b4b9f80bc229572\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run casual-snipe-63 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/99edeac9414d46c1a52fb9730acc280d\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run funny-calf-582 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/45274d6d37da4e6fadbd698871e6ff42\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n",
      "🏃 View run skittish-crane-915 at: http://127.0.0.1:5010/#/experiments/523835007103933937/runs/279988b2347449d3b075bf56ca7a5a90\n",
      "🧪 View experiment at: http://127.0.0.1:5010/#/experiments/523835007103933937\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_f_pinn = .1",
   "id": "4032af66786bee8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"pinn_loss_factor\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "pinn_factors = set(runs_df['params.pinn_factor'].unique())\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in pinn_factors}\n",
    "for f in pinn_factors:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse + pinn') &\n",
    "        (runs_df['params.pinn_factor'] == f)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[f][metric_name].append([metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "edf0b4cbb06b16e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{float(c):.1e}\" for c in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(0, 1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "33184b3c10d06778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model capacity",
   "id": "ab13ec48e1b93b3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"model_capacity\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "n_layers_values = [2, 3, 4, 5]\n",
    "n_neurons_values = [65, 70, 80, 80, 100, 120]\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for n_layers in n_layers_values:\n",
    "        for n_neurons in n_neurons_values:\n",
    "            for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "                hidden_dims = [n_neurons for _ in range(n_layers)]\n",
    "                train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "                future = executor.submit(trial_routine, None, train,\n",
    "                                         {\n",
    "                                             'input_dim': 65,\n",
    "                                             'hidden_dims': hidden_dims,\n",
    "                                             'output_dim': 3,\n",
    "                                             'activation': \"relu\",\n",
    "                                             'activation_params': None,\n",
    "                                             'dropout': 0.0,\n",
    "                                             'batch_norm': False,\n",
    "                                             'layer_norm': False,\n",
    "                                             'normalization_params': None,\n",
    "                                             'output_activation': None,\n",
    "                                             'output_activation_params': None,\n",
    "                                         },\n",
    "                                         train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                         N_EPOCH,\n",
    "                                         torch.optim.Adam, LR, nn.MSELoss, StiffnessToLoadLoss, best_f_pinn,\n",
    "                                         kfold, log_step, {'loss': 'mse + pinn'})\n",
    "                futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "9eda5e74461afd36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"model_capacity\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "layers_combinations = set()\n",
    "for n_layers in runs_df['params.n_hidden_layers'].unique():\n",
    "    for layer_size in runs_df['params.hidden_layers_size'].unique():\n",
    "        layers_combinations.add((n_layers, layer_size))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in layers_combinations}\n",
    "for n, size in layers_combinations:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse + pinn') &\n",
    "        (runs_df['params.n_hidden_layers'] == n) &\n",
    "        (runs_df['params.hidden_layers_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[(n, size)][metric_name].append(\n",
    "                [metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "keys = list(results.keys())\n",
    "for k in keys:\n",
    "    vi = results[k].values().__iter__().__next__()\n",
    "    if len(vi) == 0: del results[k]\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "4246215ec92faf5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "_configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = _configs\n",
    "configs = sorted(configs)\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [str([int(x) for x in cfg]) for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "d07411d31cbd7161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_hidden_dims = [60 for _ in range(5)]",
   "id": "eb9cce28b95fc322",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Activation function",
   "id": "29985860626472d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"activation_function\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "activation_values = ['relu', 'gelu', 'tanh', 'sigmoid',\n",
    "                     'leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']\n",
    "activation_params_values = [None, None, None, None,\n",
    "                            {'negative_slope': 5e-1}, {'negative_slope': 1e-1}, {'negative_slope': 5e-2},\n",
    "                            {'negative_slope': 1e-2}]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for activation, activation_params in zip(activation_values, activation_params_values):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': activation,\n",
    "                                         'activation_params': activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, nn.MSELoss, StiffnessToLoadLoss, best_f_pinn,\n",
    "                                     kfold, log_step, {'loss': 'mse + pinn'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "46af388004fde135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"activation_function\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "activations_combinations = set()\n",
    "for m in runs_df['params.activation'].unique():\n",
    "    for n in runs_df[runs_df['params.activation'] == m]['params.activation_params'].unique():\n",
    "        activations_combinations.add((m, n))\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in activations_combinations}\n",
    "for k in activations_combinations:\n",
    "    (act, params) = k\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse + pinn') &\n",
    "        (runs_df['params.activation'] == act) &\n",
    "        (runs_df['params.activation_params'] == params)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[k][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "d332a819e357b074",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Your existing code for preparing the data\n",
    "configs = [x[1] for x in sorted([(np.min(v['val_mape']), k) for k, v in results.items()])]\n",
    "labels = [f\"[{cfg[0]}]\" if cfg[1] == 'None' else f\"[{cfg[0]}, {cfg[1]}]\" for cfg in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False)\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "7d53d72eb8302c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_activation = 'leaky_relu'\n",
    "best_activation_params = {'negative_slope': 1e-2}"
   ],
   "id": "eeafacaa469cbe0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning rate",
   "id": "1f5073b06c10a3ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"learning_rate\")\n",
    "\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "VAL_BATCH_SIZE = 512\n",
    "\n",
    "N_EPOCH = 200\n",
    "LR = 5e-4\n",
    "\n",
    "log_step = -1\n",
    "\n",
    "kfold = 5\n",
    "dataset_path = \"data/dataset/pratt_truss_bridge/member_ea/train_4096.hdf5\"\n",
    "ds = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for LR in sorted(np.hstack([f * np.logspace(-5, -2, 4) for f in [1, 2.5, 5, 7.5]])):\n",
    "        for fold, (train_idx, val_idx) in enumerate(KFold(n_splits=kfold, shuffle=True).split(ds)):\n",
    "            train_dataset, validation_dataset = Subset(ds, train_idx), Subset(ds, val_idx)\n",
    "            future = executor.submit(trial_routine, None, train,\n",
    "                                     {\n",
    "                                         'input_dim': 65,\n",
    "                                         'hidden_dims': best_hidden_dims,\n",
    "                                         'output_dim': 3,\n",
    "                                         'activation': best_activation,\n",
    "                                         'activation_params': best_activation_params,\n",
    "                                         'dropout': 0.0,\n",
    "                                         'batch_norm': False,\n",
    "                                         'layer_norm': False,\n",
    "                                         'normalization_params': None,\n",
    "                                         'output_activation': None,\n",
    "                                         'output_activation_params': None,\n",
    "                                     },\n",
    "                                     train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                     N_EPOCH,\n",
    "                                     torch.optim.Adam, LR, nn.MSELoss, StiffnessToLoadLoss, best_f_pinn,\n",
    "                                     kfold, log_step, {'loss': 'mse + pinn'})\n",
    "            futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "4e2bc821632feaec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"learning_rate\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "learning_rates = set(runs_df['params.learning_rate'].unique())\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in learning_rates}\n",
    "for lr in learning_rates:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse + pinn') &\n",
    "        (runs_df['params.learning_rate'] == lr)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[lr][metric_name].append([metric.value for metric in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "5db573ccdbb9ef70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs][:4]\n",
    "\n",
    "\"\"\"configs = [\n",
    " '7.5e-04',\n",
    " '5.0e-04',\n",
    " '2.5e-04',\n",
    " '1.0e-04',]\n",
    "\"\"\"\n",
    "labels = [f\"{float(c):.1e}\" for c in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(0, 1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "813b94446ea73859",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_lr = 5e-4",
   "id": "fb6c53e02e1f1063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "2a9490f82561b8eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_lr_old = best_lr\n",
    "best_lr = 5e-4\n",
    "\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"training\")\n",
    "\n",
    "VAL_BATCH_SIZE = 8192\n",
    "N_EPOCH = 1_000\n",
    "log_step = -1\n",
    "\n",
    "sizes = [2 ** i for i in range(8, 15)]\n",
    "batch_size_values = [512 for _ in sizes]  # [int(min(np.power(2, np.floor(np.log2(n)) - 1), 512)) for n in sizes]\n",
    "dataset_path_values = [f\"data/dataset/pratt_truss_bridge/member_ea/train_{n}.hdf5\" for n in sizes]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i, (dataset_path, TRAIN_BATCH_SIZE) in enumerate(zip(dataset_path_values, batch_size_values)):\n",
    "        size = sizes[i]\n",
    "        train_dataset = FixedPrattTrussDatasetThreeTargets(dataset_path)\n",
    "        validation_dataset = _validation_ds\n",
    "        future = executor.submit(trial_routine, None, train,\n",
    "                                 {\n",
    "                                     'input_dim': 65,\n",
    "                                     'hidden_dims': best_hidden_dims,\n",
    "                                     'output_dim': 3,\n",
    "                                     'activation': best_activation,\n",
    "                                     'activation_params': best_activation_params,\n",
    "                                     'dropout': 0.0,\n",
    "                                     'batch_norm': False,\n",
    "                                     'layer_norm': False,\n",
    "                                     'normalization_params': None,\n",
    "                                     'output_activation': None,\n",
    "                                     'output_activation_params': None\n",
    "                                 },\n",
    "                                 train_dataset, validation_dataset, TRAIN_BATCH_SIZE, VAL_BATCH_SIZE,\n",
    "                                 N_EPOCH,\n",
    "                                 torch.optim.Adam, best_lr, nn.MSELoss, StiffnessToLoadLoss, best_f_pinn,\n",
    "                                 -1, log_step, {'loss': 'pinn', 'noise': 0.})\n",
    "        futures.append(future)\n",
    "\n",
    "    # Ensure all processes complete execution\n",
    "    for future in futures:\n",
    "        future.result()"
   ],
   "id": "9eac9b92b65a51a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "cols = [c for c in runs_df if c.startswith('metrics.')]\n",
    "metrics_names = [col[col.index('.') + 1:] for col in cols]\n",
    "\n",
    "sizes = set()\n",
    "for size in runs_df['params.train_size'].unique():\n",
    "    sizes.add(size)\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "results = {k1: {k2: [] for k2 in metrics_names} for k1 in sizes}\n",
    "for size in sizes:\n",
    "    run_ids = runs_df[\n",
    "        (runs_df['params.loss'] == 'mse + pinn') &\n",
    "        (runs_df['params.train_size'] == size)\n",
    "        ]['run_id']\n",
    "    for run_id in run_ids:\n",
    "        for metric_name in metrics_names:\n",
    "            results[size][metric_name].append([m.value for m in client.get_metric_history(run_id, metric_name)])\n",
    "\n",
    "for k in results.keys():\n",
    "    for metric in results[k].keys():\n",
    "        results[k][metric] = np.vstack(results[k][metric]).mean(axis=0)"
   ],
   "id": "cb9b67c6fb4d0ccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "configs = sorted([(np.min(v['val_mape']), k) for k, v in results.items()])\n",
    "configs = [x[1] for x in configs]\n",
    "\n",
    "labels = [f\"{int(size)}\" for size in configs]\n",
    "\n",
    "plot(results, configs, 'loss', labels)\n",
    "plot(results, configs, 'mape', labels)\n",
    "plot(results, configs, 'r2', labels, log=False, ylim=(-.2, 1.1))\n",
    "plot(results, configs, 'rmse_MN', labels)"
   ],
   "id": "a9536f85ed5e86cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Noise sensitivity",
   "id": "919f95eee4416502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "experiment = mlflow.get_experiment_by_name(\"training\")\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "results = []\n",
    "\n",
    "for f in np.linspace(0, .1, 6):\n",
    "    validation_ds = FixedPrattTrussDatasetThreeTargets(\n",
    "        \"data/dataset/pratt_truss_bridge/member_ea/validation_8192.hdf5\",\n",
    "        f_noise_length=None,\n",
    "        f_noise_loads=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_strain=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "        f_noise_displacement=lambda size: np.random.normal(1, f / 4, size=size),\n",
    "    )\n",
    "\n",
    "    dl = DataLoader(validation_ds, batch_size=8192)\n",
    "\n",
    "    for i in range(len(runs_df[['artifact_uri', 'params.train_size']])):\n",
    "        artifact_uri = runs_df.iloc[i]['artifact_uri']\n",
    "        size = runs_df.iloc[i]['params.train_size']\n",
    "\n",
    "        uri = f\"{artifact_uri}/input_scaler/\"\n",
    "        input_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/target_scaler/\"\n",
    "        target_scaler = load_model(uri)\n",
    "\n",
    "        uri = f\"{artifact_uri}/mape_model/\"\n",
    "        model = load_model(uri)\n",
    "\n",
    "        for batch in dl:\n",
    "            metrics = validation(model, batch, input_scaler, target_scaler, F.mse_loss)\n",
    "        results.append((size, f, metrics))"
   ],
   "id": "12a92d05d4b44962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlflow.set_tracking_uri(uri=MLFLOW_URI(port=PORT))\n",
    "mlflow.set_experiment(\"noise_sensitivity\")\n",
    "\n",
    "df = pd.DataFrame([[results[i][0], results[i][1],\n",
    "                    results[i][2]['r2'].item(),\n",
    "                    results[i][2]['mape'].item(),\n",
    "                    results[i][2]['rmse_MN'].item(),\n",
    "                    results[i][2]['loss']]\n",
    "                   for i in range(len(results))], columns=['train_size', 'noise', 'r2', 'mape', 'rmse_MN', 'loss'])\n",
    "df.sort_values(by=['train_size', 'noise'], axis=0, ignore_index=True, inplace=True)\n",
    "\n",
    "for size in df.train_size.unique():\n",
    "    with mlflow.start_run():\n",
    "        df_2 = df[df['train_size'] == size]\n",
    "        # Model information logging\n",
    "        mlflow.log_params({\n",
    "            'train_size': size,\n",
    "            'loss': 'mse'\n",
    "        })\n",
    "        for i in range(len(df_2)):\n",
    "            mlflow.log_metrics(\n",
    "                dict(df_2.iloc[i][1:]),\n",
    "                step=i\n",
    "            )"
   ],
   "id": "9b1d000d29a3607",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
