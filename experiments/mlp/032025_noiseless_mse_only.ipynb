{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:00:57.323369Z",
     "start_time": "2025-03-10T09:00:57.318566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "figure_dir = os.getcwd() + '/022025_experiment/figures'"
   ],
   "id": "202768c7e6a8e792",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:00:57.693590Z",
     "start_time": "2025-03-10T09:00:57.690712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from default import PROJECT_HOME\n",
    "%cd -q {PROJECT_HOME}"
   ],
   "id": "69b7af63f95cab1a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-10T09:47:14.620252Z",
     "start_time": "2025-03-10T09:47:14.614862Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import mlflow\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.architecture import MLP\n",
    "from models.processing import StandardScaler\n",
    "from torch import nn\n",
    "\n",
    "import torchmetrics.functional.regression as R\n",
    "from dataset import FixedPrattTrussDatasetSingleTarget\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train procedures",
   "id": "767acb282c7311ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T09:48:40.247670Z",
     "start_time": "2025-03-10T09:47:18.422141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_step(model, batch, input_scaler, target_scaler, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    input, target, _, _, _ = batch\n",
    "    input, target = input.to(device), target.to(device)\n",
    "\n",
    "    z_input = input_scaler.transform(input)\n",
    "    z_target = target_scaler.transform(target)\n",
    "\n",
    "    z_target_pred = model(z_input)\n",
    "    target_pred = target_scaler.inverse_transform(target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(z_target_pred, z_target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def validation(model, batch, input_scaler, target_scaler, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        z_input = input_scaler.transform(input)\n",
    "        z_target = target_scaler.transform(target)\n",
    "\n",
    "        z_target_pred = model(z_input)\n",
    "        target_pred = target_scaler.inverse_transform(target)\n",
    "\n",
    "        loss = criterion(z_target_pred, z_target)\n",
    "\n",
    "    metrics = compute_metrics(model, target_pred, z_target_pred, target, z_target)\n",
    "    metrics['loss'] = loss.item()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def compute_metrics(model, target_pred, z_target_pred, target, z_target):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        r2 = R.r2_score(target_pred, target)\n",
    "        if r2.isinf():  # Switch to 64 bits in case of overflow\n",
    "            r2 = R.r2_score(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64))\n",
    "        mape = R.mean_absolute_percentage_error(target_pred, target)\n",
    "        rmse = R.mean_squared_error(target_pred, target, squared=False)\n",
    "        if rmse.isinf():  # Switch to 64 bits in case of overflow\n",
    "            rmse = R.mean_squared_error(target_pred.cpu().to(torch.float64), target.cpu().to(torch.float64),\n",
    "                                        squared=False)\n",
    "\n",
    "    return {'r2': r2, 'mape': mape, 'rmse': rmse}\n",
    "\n",
    "\n",
    "def log_epoch(train_metrics, val_metrics, epoch):\n",
    "    metrics = dict()\n",
    "    metrics.update({f'train_{k}': v for k, v in train_metrics.items()})\n",
    "    metrics.update({f'val_{k}': v for k, v in val_metrics.items()})\n",
    "\n",
    "    mlflow.log_metrics(metrics, step=epoch)\n",
    "\n",
    "\n",
    "def log_model(name, model, signature, metadata=None):\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=name,\n",
    "        signature=signature,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion):\n",
    "    train_dl = DataLoader(train_dataset, train_batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_dataset, val_batch_size, shuffle=True)\n",
    "\n",
    "    input_scaler = StandardScaler(train_dataset[0][0].__len__()).to(device)\n",
    "    target_scaler = StandardScaler(train_dataset[0][1].__len__()).to(device)\n",
    "\n",
    "    # Train the scaler\n",
    "    input, target = None, None\n",
    "    for batch in train_dl:\n",
    "        input, target, _, _, _ = batch\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        input_scaler.partial_fit(input)\n",
    "        target_scaler.partial_fit(target)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(),\n",
    "                                              input_scaler.transform(input).cpu().detach().numpy())\n",
    "    log_model('input_scaler', input_scaler, signature=signature)\n",
    "\n",
    "    signature = mlflow.models.infer_signature(target.cpu().detach().numpy(),\n",
    "                                              target_scaler.transform(target).cpu().detach().numpy())\n",
    "    log_model('target_scaler', target_scaler, signature=signature)\n",
    "\n",
    "    best_val_metric = {\n",
    "        'mape': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'rmse': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'loss': {model: None, 'value': np.inf, 'epoch': -1},\n",
    "        'r2': {model: None, 'value': -np.inf, 'epoch': -1}\n",
    "    }\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        train_metrics = {}\n",
    "        val_metrics = {}\n",
    "        for batch in train_dl:\n",
    "            train_metrics_epoch = train_step(model, batch, input_scaler, target_scaler, optimizer, criterion)\n",
    "            for k, m in train_metrics_epoch.items():\n",
    "                if k not in train_metrics: train_metrics[k] = []\n",
    "                train_metrics[k].append(m)\n",
    "\n",
    "        for batch in val_dl:\n",
    "            val_metrics_epoch = validation(model, batch, input_scaler, target_scaler, criterion)\n",
    "            for k, m in val_metrics_epoch.items():\n",
    "                if k not in val_metrics: val_metrics[k] = []\n",
    "                val_metrics[k].append(m)\n",
    "\n",
    "        # Compute the mean on GPU  -> Faster for batch\n",
    "        train_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                         train_metrics.items()}\n",
    "        val_metrics = {name: torch.tensor(metrics, device=device, dtype=torch.float32).mean() for name, metrics in\n",
    "                       val_metrics.items()}\n",
    "\n",
    "        log_epoch(train_metrics, val_metrics, epoch)\n",
    "\n",
    "        negative_metrics = {'r2'}  # Set of metrics which are better when higher\n",
    "        for k, v in best_val_metric.items():\n",
    "            v = v['value'] if k in negative_metrics else - v['value']\n",
    "            if best_val_metric[k]['value'] <= v:\n",
    "                best_val_metric[k] = {'model': deepcopy(model.to('cpu', copy=True)), 'value': v, 'epoch': epoch}\n",
    "\n",
    "        print(f\"epoch: {epoch}\")\n",
    "\n",
    "    input, target, _, _, _ = train_dl.__iter__().__next__()\n",
    "    signature = mlflow.models.infer_signature(input.cpu().detach().numpy(), target.cpu().detach().numpy())\n",
    "    for k, (m, val, epoch) in best_val_metric.items():\n",
    "        log_model(f\"{k}_model\", m, signature=signature, metadata={'metric': val, 'epoch': epoch})\n",
    "\n",
    "\n",
    "ds_1 = FixedPrattTrussDatasetSingleTarget(\"data/dataset/pratt_truss_bridge/single_ea/train_10000.hdf5\")\n",
    "ds_2 = FixedPrattTrussDatasetSingleTarget(\"data/dataset/pratt_truss_bridge/single_ea/test_10000.hdf5\")\n",
    "in_dim = ds_1[0][0].__len__()\n",
    "model = MLP(in_dim, (100, 100, 100), 1, 'relu').to(device)\n",
    "train(model, ds_1, ds_2, 4096, 8192, 2, torch.optim.Adam(model.parameters(), lr=2e-4), nn.MSELoss())"
   ],
   "id": "2768832a5f3dd7aa",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 148\u001B[0m\n\u001B[1;32m    146\u001B[0m in_dim \u001B[38;5;241m=\u001B[39m ds_1[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m()\n\u001B[1;32m    147\u001B[0m model \u001B[38;5;241m=\u001B[39m MLP(in_dim, (\u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m100\u001B[39m), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m--> 148\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mds_2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4096\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8192\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2e-4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMSELoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[14], line 131\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion)\u001B[0m\n\u001B[1;32m    128\u001B[0m log_epoch(train_metrics, val_metrics, epoch)\n\u001B[1;32m    130\u001B[0m negative_metrics \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m}  \u001B[38;5;66;03m# Set of metrics which are better when higher\u001B[39;00m\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m best_val_metric\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    132\u001B[0m     v \u001B[38;5;241m=\u001B[39m v[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m negative_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m v[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m best_val_metric[k][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m v:\n",
      "Cell \u001B[0;32mIn[14], line 131\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_dataset, val_dataset, train_batch_size, val_batch_size, n_epoch, optimizer, criterion)\u001B[0m\n\u001B[1;32m    128\u001B[0m log_epoch(train_metrics, val_metrics, epoch)\n\u001B[1;32m    130\u001B[0m negative_metrics \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr2\u001B[39m\u001B[38;5;124m'\u001B[39m}  \u001B[38;5;66;03m# Set of metrics which are better when higher\u001B[39;00m\n\u001B[0;32m--> 131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m best_val_metric\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    132\u001B[0m     v \u001B[38;5;241m=\u001B[39m v[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m negative_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m v[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m best_val_metric[k][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m v:\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning",
   "id": "b5df830a1a285165"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e752cc9aff4e6aa3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "c454d4e7fa6dbb9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4a06e8b1ffdbc449"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "7d4fa75c9189fd51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e09504b1f94b195d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
