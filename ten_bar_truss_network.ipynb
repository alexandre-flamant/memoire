{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-14T20:21:55.284812Z",
     "start_time": "2024-12-14T20:21:52.263432Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import TenBarsPlanarTrussDataset\n",
    "from loss import DirectStiffnessLoss, construct_k_from_ea\n",
    "from models.architecture import MultiLayerPerceptron"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T20:21:55.298120Z",
     "start_time": "2024-12-14T20:21:55.294339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filepath = {\n",
    "    'train': \"data/dataset/10_bar_truss/train/data.hdf5\",\n",
    "    'validation': \"data/dataset/10_bar_truss/validation/data.hdf5\",\n",
    "    'test': \"data/dataset/10_bar_truss/test/data.hdf5\"\n",
    "}"
   ],
   "id": "107648bfbcf1798a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T20:21:56.082541Z",
     "start_time": "2024-12-14T20:21:55.303645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layers = [50, 50, 50]\n",
    "model = MultiLayerPerceptron(25, layers, 10)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "fn_loss_data = nn.MSELoss()\n",
    "fn_loss_physics = DirectStiffnessLoss()"
   ],
   "id": "d02c41f3e0accc51",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T20:21:58.223692Z",
     "start_time": "2024-12-14T20:21:56.147094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_EPOCH = 3\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "_train_dataset = TenBarsPlanarTrussDataset(filepath['train'])\n",
    "_test_dataset = TenBarsPlanarTrussDataset(filepath['test'])\n",
    "_validation_dataset = TenBarsPlanarTrussDataset(filepath['validation'])\n",
    "\n",
    "train_dataloader = DataLoader(_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=1, persistent_workers=True)\n",
    "test_dataloader = DataLoader(_test_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                             num_workers=1, persistent_workers=True)\n",
    "validation_dataloader = DataLoader(_validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                   num_workers=1, persistent_workers=True)\n",
    "\n",
    "connectivity = torch.tensor([[0, 1, 3, 4, 1, 2, 0, 3, 1, 4],\n",
    "                             [1, 2, 4, 5, 4, 5, 4, 1, 5, 2]]).T\n",
    "\n",
    "support = torch.tensor([0, 1, 6, 7])"
   ],
   "id": "3e108559862bab33",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T20:22:28.396396Z",
     "start_time": "2024-12-14T20:21:58.247471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = './_runs/EA_prediction_{}'.format(timestamp)\n",
    "\n",
    "if not os.path.exists(f\"{log_dir}/log\"):\n",
    "    os.makedirs(f\"{log_dir}/log\")\n",
    "    \n",
    "if not os.path.exists(f\"{log_dir}/weights\"):\n",
    "    os.makedirs(f\"{log_dir}/weights\")\n",
    "    \n",
    "writer = SummaryWriter(log_dir + \"/log\")\n",
    "\n",
    "best_v_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    loop = tqdm(enumerate(train_dataloader), total=len(train_dataloader), leave=True)\n",
    "    loop.set_description(f'Epoch {epoch + 1:3d}/{N_EPOCH}')\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_physic_loss = 0.\n",
    "    running_data_loss = 0.\n",
    "\n",
    "    last_loss = np.inf\n",
    "    last_data_loss = np.inf\n",
    "    last_physic_loss = np.inf\n",
    "\n",
    "    model.train(True)\n",
    "    for i, data in loop:\n",
    "        inputs, target, nodes, _, u, q = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ea_pred = model(inputs)\n",
    "        k_pred = construct_k_from_ea(ea_pred, nodes, connectivity, support)\n",
    "\n",
    "        loss_data = fn_loss_data(ea_pred, target)\n",
    "        loss_physic = fn_loss_physics(k_pred, u, q)\n",
    "        loss = loss_data + loss_physic\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss_data.item()\n",
    "        running_physic_loss += loss_physic.item()\n",
    "        running_data_loss += loss_data.item()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10\n",
    "            last_physic_loss = running_physic_loss / 10\n",
    "            last_data_loss = running_data_loss / 10\n",
    "\n",
    "            tb_x = epoch * len(train_dataloader) + i + 1\n",
    "            writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            writer.add_scalar('Physics_loss/train', last_physic_loss, tb_x)\n",
    "            writer.add_scalar('Data_loss/train', last_data_loss, tb_x)\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_physic_loss = 0.\n",
    "            running_data_loss = 0.\n",
    "\n",
    "        loop.set_postfix({\n",
    "            'train loss': running_loss,\n",
    "            'train MSE': running_data_loss,\n",
    "            'train Phys. loss': running_physic_loss,\n",
    "        })\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_loss = 0\n",
    "        v_loss_data = 0\n",
    "        v_loss_physic = 0\n",
    "        for data in validation_dataloader:\n",
    "            inputs, target, nodes, _, u, q = data\n",
    "\n",
    "            ea_pred = model(inputs)\n",
    "            k_pred = construct_k_from_ea(ea_pred, nodes, connectivity, support)\n",
    "\n",
    "            v_loss_data += fn_loss_data(ea_pred, target).item()\n",
    "            v_loss_physic += fn_loss_physics(k_pred, u, q).item()\n",
    "            v_loss += loss_data.item() + loss_physic.item()\n",
    "\n",
    "    v_loss /= len(validation_dataloader.dataset)\n",
    "    v_loss_data /= len(validation_dataloader.dataset)\n",
    "    v_loss_physic /= len(validation_dataloader.dataset)\n",
    "\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training loss': last_loss,\n",
    "                        'Training data loss': last_data_loss,\n",
    "                        'Training physics loss': last_physic_loss,\n",
    "                        'Validation loss': v_loss,\n",
    "                        'Validation data loss': v_loss_data,\n",
    "                        'Validation physics loss': v_loss_physic, },\n",
    "                       epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Validation Loss: {v_loss:.4f}, Validation MSE: {v_loss_data:.4f}, Validation Phys. Loss: {v_loss_physic:.4f}\")\n",
    "\n",
    "    if v_loss < best_v_loss:\n",
    "        best_vloss = v_loss\n",
    "        model_path = f\"{log_dir}/weights/model_{timestamp}_{epoch}\"\n",
    "        torch.save(model.state_dict(), model_path)\n"
   ],
   "id": "2149a736eeb80e2c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   1/3: 100%|██████████| 391/391 [00:08<00:00, 44.82it/s, train loss=2.75e+16, train MSE=2.75e+16, train Phys. loss=2.11e+9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 108571829812853.1250, Validation MSE: 125463980693939.0469, Validation Phys. Loss: 11490762.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   2/3: 100%|██████████| 391/391 [00:08<00:00, 46.92it/s, train loss=3.32e+16, train MSE=3.32e+16, train Phys. loss=2.34e+9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 131239672947278.4688, Validation MSE: 124534806885412.2188, Validation Phys. Loss: 13597599.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch   3/3: 100%|██████████| 391/391 [00:08<00:00, 47.87it/s, train loss=2.74e+16, train MSE=2.74e+16, train Phys. loss=4.45e+9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 108336592585383.8906, Validation MSE: 124008457312578.1562, Validation Phys. Loss: 14064472.0716\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7e7fc70e4febcdc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
