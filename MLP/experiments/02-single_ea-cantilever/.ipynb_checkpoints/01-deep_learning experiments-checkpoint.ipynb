{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from imghdr import tests\n",
    "%pwd\n",
    "%cd ../.."
   ],
   "id": "58fd7167621b4c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RANDOM_STATE = 42\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (d2_absolute_error_score as D2,\n",
    "                             r2_score as R2,\n",
    "                             mean_absolute_percentage_error as MAPE)\n",
    "\n",
    "from dataset import TenBarsCantileverTrussSingleEADataset\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from models.architecture import MultiLayerPerceptron\n",
    "from models.processing import StandardScaler\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available()\n",
    "    else 'cpu'\n",
    ")"
   ],
   "id": "f073667fcbebe50c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Load the data\n",
   "id": "6567808ced4fe2b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_path = \"./data/dataset/cantilever/data.hdf5\"\n",
    "_ds = TenBarsCantileverTrussSingleEADataset(data_path)\n",
    "\n",
    "in_dim = _ds[0][0].__len__()\n",
    "out_dim = _ds[0][1].__len__()\n",
    "\n",
    "print(f\"Dataset size: {len(_ds)}\")\n",
    "print(f\"  Sample dimension: {in_dim}\")\n",
    "print(f\"  Target dimension: {out_dim}\")"
   ],
   "id": "5502a7293587797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Training and Validation routine",
   "id": "93760e7333b6f0e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "MAPE([1.1,1.1], [1,1])",
   "id": "c23131b65fe112fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T15:25:13.718802Z",
     "start_time": "2025-02-11T15:25:13.712217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, train_ds, val_ds, lr, n_epochs, batch_size, verbose=True):\n",
    "    model = model.to(device)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    x_scaler = StandardScaler(in_dim).to(device)\n",
    "    y_scaler = StandardScaler(out_dim).to(device)\n",
    "    for x, y, _, _, _ in train_dl:\n",
    "        x_scaler.partial_fit(x.to(device))\n",
    "        y_scaler.partial_fit(y.to(device))\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        train_MSE = []\n",
    "        train_MAPE = []\n",
    "        train_R2 = []\n",
    "        train_D2 = []\n",
    "\n",
    "        for batch in train_dl:\n",
    "            x, y, _, _, _ = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            x = x_scaler.transform(x)\n",
    "            y = y_scaler.transform(y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y, y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            y_unscaled = y_scaler.inverse_transform(y)\n",
    "            y_pred_unscaled = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            train_MSE.append(F.mse_loss(y_pred_unscaled, y_unscaled).item())\n",
    "            train_MAPE.append(MAPE(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "            train_D2.append(D2(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "            train_R2.append(R2(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        val_MSE = []\n",
    "        val_MAPE = []\n",
    "        val_R2 = []\n",
    "        val_D2 = []\n",
    "        for batch in val_dl:\n",
    "            x, y, _, _, _ = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            x = x_scaler.transform(x)\n",
    "            y = y_scaler.transform(y)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            y_unscaled = y_scaler.inverse_transform(y)\n",
    "            y_pred_unscaled = y_scaler.inverse_transform(y_pred)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            val_MSE.append(F.mse_loss(y_pred_unscaled, y_unscaled).item())\n",
    "            val_MAPE.append(MAPE(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "            val_D2.append(D2(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "            val_R2.append(R2(y_unscaled.cpu().detach(), y_pred_unscaled.cpu().detach()))\n",
    "\n",
    "        # mlflow.log_metric(\"train loss\", np.mean(train_loss)), step=epoch)\n",
    "        # mlflow.log_metric(\"train MSE\", np.mean(train_MSE), step=epoch)\n",
    "        # mlflow.log_metric(\"train MAPE\", np.mean(train_MAPE), step=epoch)\n",
    "        # mlflow.log_metric(\"train R2\", np.mean(train_R2), step=epoch)\n",
    "        # mlflow.log_metric(\"train D2\", np.mean(train_D2), step=epoch)\n",
    "        #\n",
    "        # mlflow.log_metric(\"val loss\", np.mean(val_loss), step=epoch)\n",
    "        # mlflow.log_metric(\"val MSE\", np.mean(val_MSE), step=epoch)\n",
    "        # mlflow.log_metric(\"val MAPE\", np.mean(val_MAPE), step=epoch)\n",
    "        # mlflow.log_metric(\"val R2\", np.mean(val_R2), step=epoch)\n",
    "        # mlflow.log_metric(\"val D2\", np.mean(val_D2), step=epoch)\n",
    "\n",
    "        # Logging\n",
    "        if verbose:\n",
    "            print(f\"[Epoch {epoch + 1:{len(str(n_epochs))}d}/{n_epochs:d}]\", end='  ')\n",
    "            print(f\"TRAIN\", end='   ')\n",
    "            print(f\"Loss: {np.mean(train_loss):1.4f}\", end = ',  ')\n",
    "            print(f\"MSE: {np.mean(train_MSE):1.4e}\", end = ',  ')\n",
    "            print(f\"MAPE: {np.mean(train_MAPE):1.4f}\", end = ',  ')\n",
    "            print(f\"R2: {np.mean(train_R2):1.4f}\", end = ',  ')\n",
    "            print(f\"D2: {np.mean(train_D2):1.4f}\", end = '')\n",
    "            print(\"  ||  \", end='')\n",
    "            print(f\"VALIDATION\", end='   ')\n",
    "            print(f\"Loss: {np.mean(val_loss):1.4f}\", end = ',  ')\n",
    "            print(f\"MSE: {np.mean(val_MSE):1.4e}\", end = ',  ')\n",
    "            print(f\"MAPE: {np.mean(val_MAPE):1.4f}\", end = ',  ')\n",
    "            print(f\"R2: {np.mean(val_R2):1.4f}\", end = ',  ')\n",
    "            print(f\"D2: {np.mean(val_D2):1.4f}\")"
   ],
   "id": "48a74fff01e9b052",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-11T15:25:16.162578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_1, ds_2 = random_split(_ds, (.8, .2))\n",
    "train(model = MultiLayerPerceptron(in_dim, out_dim,\n",
    "                                             40,3,\n",
    "                                             nn.ReLU),\n",
    "      train_ds = ds_1,\n",
    "      lr=4e-4,\n",
    "      val_ds = ds_2,\n",
    "      n_epochs = 100,\n",
    "      batch_size = 2048,\n",
    "      verbose = True)"
   ],
   "id": "8daca2f352fb702e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # 2. Hyperparameter tuning\n",
    "Considering a 10 bar cantilever dataset we want to predict the EA of the bars which is assumed to be a single common value.\n",
    "The model is an MLP here are the parameters:\n",
    "- Activation function\n",
    "- Learning rate\n",
    "- Number of layers\n",
    "- Number of neurons per layer"
   ],
   "id": "180279513a44999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model capacity tuning\n",
    "n_neurons_values = [10, 15, 20, 25, 30]\n",
    "n_layers_values = [2, 3, 4, 5]\n",
    "\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "outer_configs = []\n",
    "outer_scores = []\n",
    "for outer_fold_id, (train_idx, test_idx) in enumerate(outer_cv.split(_ds)):\n",
    "    train_ds, test_ds = Subset(_ds, train_idx), Subset(_ds, test_idx)\n",
    "\n",
    "    inner_cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE + outer_fold_id)\n",
    "    inner_scores = {}\n",
    "    for n_neurons in n_neurons_values:\n",
    "        for n_layers in n_layers_values:\n",
    "            inner_scores.setdefault((n_layers, n_neurons), [])\n",
    "            for inner_fold_id, (train_idx, val_idx) in inner_cv.split(train_ds):\n",
    "                train_ds, val_ds = Subset(train_ds, train_idx), Subset(train_ds, val_idx)\n",
    "\n",
    "                model = MultiLayerPerceptron(in_dim, out_dim,\n",
    "                                             n_layers, n_neurons,\n",
    "                                             nn.ReLU)\n",
    "\n",
    "                train(model, train_ds, val_ds)\n",
    "\n",
    "                inner_scores[(n_layers, n_neurons)].append(score)\n",
    "\n",
    "    best_score = np.inf\n",
    "    best_config = None\n",
    "    for config, scores in inner_scores.items():\n",
    "        if scores < best_score:\n",
    "            best_score = scores\n",
    "            best_config = config\n",
    "\n",
    "    model = MultiLayerPerceptron(in_dim, out_dim,\n",
    "                                 best_config[0], best_config[1],\n",
    "                                 nn.ReLU)\n",
    "\n",
    "    train(model, train_ds, test_ds)\n",
    "    score = validate(model, test_ds)\n",
    "\n",
    "    outer_configs.append(best_config)\n",
    "    outer_scores.append(score)"
   ],
   "id": "bc2d7655211f1194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Training the foundation model\n",
    "We will train our model with the whole dataset to create a foundation model that will have learnt all the specifics of the problem."
   ],
   "id": "5f0fd2f63ce01e6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4844ba1bf8bede59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Prediction on real data\n",
    "We will use as *real* data, data with shared multiplicative noise:\n",
    "$$\\varepsilon \\sim \\mathcal N \\left( \\mu = 1, \\sigma = 0.0025 \\right)$$\n",
    "\n",
    "Such that $\\hat x = x * \\varepsilon$ has 95% chance of being within +- 0.5% of the true value. Which is the same order of magnitude observed with HBM sensors.\n",
    "\n",
    "This noise will be applied to a set of data from which a subset will be extracted for fine-tuning."
   ],
   "id": "3d54db98c5c73fbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## a. Non fine-tuned prediction\n",
    "Scores using the foundation model for prediction"
   ],
   "id": "29dadd240cc35cd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5d4bf08b6103e02e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "z## b. Fine-tuned model\n",
    "We will finetune the foundation model using the subset of real data as input\n"
   ],
   "id": "5dd04240f84aaa01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f19781d1424e6ab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### I. Experiment on the size of fine-tuning set\n",
    "These experiments will help us define how many real example are needed for *sufficient* fine-tuning."
   ],
   "id": "a5058d47065dfffa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Without PINN",
   "id": "2ad2ad24581a628f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fde930edda682760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### With PINN",
   "id": "bf331aa03af2263a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bca8c4bd40d754ff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
