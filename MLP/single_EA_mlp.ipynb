{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:45.611215Z",
     "start_time": "2024-12-24T11:27:45.603641Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import TenBarsCantileverTrussSingleEADataset\n",
    "from models.architecture import MultiLayerPerceptron\n",
    "from models.processing import StandardScaler\n",
    "import optuna\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:46.231711Z",
     "start_time": "2024-12-24T11:27:46.227964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filepath = {\n",
    "    'train': \"data/dataset/10_bar_truss/train/data.hdf5\",\n",
    "    'validation': \"data/dataset/10_bar_truss/validation/data.hdf5\",\n",
    "    'test': \"data/dataset/10_bar_truss/test/data.hdf5\"\n",
    "}"
   ],
   "id": "107648bfbcf1798a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:50.840907Z",
     "start_time": "2024-12-24T11:27:47.872565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_EPOCH = 100\n",
    "BATCH_SIZE = 256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "_train_dataset = TenBarsCantileverTrussSingleEADataset(filepath['train'])\n",
    "_test_dataset = TenBarsCantileverTrussSingleEADataset(filepath['test'])\n",
    "_validation_dataset = TenBarsCantileverTrussSingleEADataset(filepath['validation'])\n",
    "\n",
    "train_dataloader = DataLoader(_train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=1, persistent_workers=True)\n",
    "test_dataloader = DataLoader(_test_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                             num_workers=1, persistent_workers=True)\n",
    "validation_dataloader = DataLoader(_validation_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                   num_workers=1, persistent_workers=True)\n",
    "\n",
    "connectivity = torch.tensor([[0, 1, 3, 4, 1, 2, 0, 3, 1, 4],\n",
    "                             [1, 2, 4, 5, 4, 5, 4, 1, 5, 2]]).T\n",
    "\n",
    "support = torch.tensor([0, 1, 6, 7])"
   ],
   "id": "3e108559862bab33",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T11:27:52.958320Z",
     "start_time": "2024-12-24T11:27:52.953247Z"
    }
   },
   "cell_type": "code",
   "source": "_train_dataset[0][0].shape",
   "id": "94ff39f3c90a268",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:40:04.755162Z",
     "start_time": "2024-12-17T13:39:59.804842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler_input = StandardScaler(22).to(device)\n",
    "scaler_target = StandardScaler(1).to(device)\n",
    "\n",
    "for input, target, _, _, _ in train_dataloader:\n",
    "    scaler_input.partial_fit(input.to(device))\n",
    "    scaler_target.partial_fit(target.to(device))"
   ],
   "id": "3e4ce0e33cc68cb8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression with kPCA",
   "id": "781e135db2a8a65b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:45:40.626173Z",
     "start_time": "2024-12-17T13:45:32.337871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = []\n",
    "y = []\n",
    "for x_i, y_i, _, _, _ in torch.utils.data.ConcatDataset((_train_dataset, _test_dataset)):\n",
    "    x.append(x_i.cpu().detach().numpy())\n",
    "    y.append(y_i.cpu().detach().numpy())\n"
   ],
   "id": "6d23ac4c01460355",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:45:53.846811Z",
     "start_time": "2024-12-17T13:45:53.829809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe_1 = sk.pipeline.Pipeline([\n",
    "    ('scaler', sk.preprocessing.StandardScaler()),\n",
    "    ('kpca', KernelPCA()),\n",
    "    ('estimator', LinearRegression())\n",
    "])\n",
    "\n",
    "model = TransformedTargetRegressor(regressor=pipe_1, transformer=StandardScaler())"
   ],
   "id": "84ba56ed49b85f94",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StandardScaler.__init__() missing 1 required positional argument: 'n_features'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LinearRegression\n\u001B[0;32m      3\u001B[0m pipe_1 \u001B[38;5;241m=\u001B[39m sk\u001B[38;5;241m.\u001B[39mpipeline\u001B[38;5;241m.\u001B[39mPipeline([\n\u001B[0;32m      4\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m'\u001B[39m, sk\u001B[38;5;241m.\u001B[39mpreprocessing\u001B[38;5;241m.\u001B[39mStandardScaler()),\n\u001B[0;32m      5\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkpca\u001B[39m\u001B[38;5;124m'\u001B[39m, KernelPCA()),\n\u001B[0;32m      6\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m'\u001B[39m, LinearRegression())\n\u001B[0;32m      7\u001B[0m ])\n\u001B[1;32m----> 9\u001B[0m model \u001B[38;5;241m=\u001B[39m TransformedTargetRegressor(regressor\u001B[38;5;241m=\u001B[39mpipe_1, transformer\u001B[38;5;241m=\u001B[39mStandardScaler())\n",
      "\u001B[1;31mTypeError\u001B[0m: StandardScaler.__init__() missing 1 required positional argument: 'n_features'"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def conditional_param_distributions(n_iter=50, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    param_list = []\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Randomly select a kernel\n",
    "        kernel = random.choice(['rbf', 'poly', 'sigmoid', 'rbf', 'cosine'])\n",
    "\n",
    "        # Base parameters\n",
    "        params = {\n",
    "            'regressor__kpca__kernel': kernel,\n",
    "            'regressor__kpca__n_components': np.random.randint(5, 20),  # n_components between 5 and 10\n",
    "        }\n",
    "\n",
    "        # Conditional parameters based on kernel type\n",
    "        if kernel in ['poly', 'rbf', 'sigmoid']:\n",
    "            params['regressor__kpca__gamma'] = sp.stats.uniform(0, 5)  # gamma in range [0, 5]\n",
    "        if kernel in ['poly']:\n",
    "            params['regressor__kpca__degree'] = random.randint(1, 6)  # degree: 1, 2, 3, 4, 5\n",
    "        if kernel in ['poly', 'sigmoid']:\n",
    "            params['regressor__kpca__coef0'] = sp.stats.uniform(0, 5)  # coef0 in range [0, 5]\n",
    "\n",
    "        # Append to list\n",
    "        param_list.append(params)\n",
    "\n",
    "    return param_list\n",
    "\n",
    "\n",
    "# Generate conditional parameter combinations\n",
    "param_distributions = conditional_param_distributions(n_iter=50)\n",
    "\n",
    "# RandomizedSearchCV with custom parameter sampling\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    scoring='r2',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "ec6de474a1d36de6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# No PINN",
   "id": "2f2c4aebc9bafb76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:04:49.119403Z",
     "start_time": "2024-12-16T11:04:48.131667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layers = [20, 20, 20]\n",
    "model = MultiLayerPerceptron(22, layers, 1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "fn_loss = nn.MSELoss().to(device)"
   ],
   "id": "d02c41f3e0accc51",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T11:08:29.682193Z",
     "start_time": "2024-12-16T11:07:54.971554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "log_dir = './_runs/Single_EA_prediction_{}'.format(timestamp)\n",
    "\n",
    "if not os.path.exists(f\"{log_dir}/log\"):\n",
    "    os.makedirs(f\"{log_dir}/log\")\n",
    "\n",
    "if not os.path.exists(f\"{log_dir}/weights\"):\n",
    "    os.makedirs(f\"{log_dir}/weights\")\n",
    "\n",
    "writer = SummaryWriter(log_dir + \"/log\")\n",
    "\n",
    "best_v_loss = np.inf\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    print(f'Epoch {epoch + 1:3d}/{N_EPOCH}')\n",
    "\n",
    "    running_loss = 0.\n",
    "    last_loss = np.inf\n",
    "\n",
    "    model.train(True)\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, target, _, _, _ = data\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        inputs = scaler_input.transform(inputs)\n",
    "        target = scaler_target.transform(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ea_pred = model(inputs)\n",
    "\n",
    "        loss = fn_loss(ea_pred, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            last_loss = running_loss / 100\n",
    "\n",
    "            tb_x = epoch * len(train_dataloader) + i + 1\n",
    "            writer.add_scalar('Loss during training', last_loss, tb_x)\n",
    "\n",
    "            running_loss = 0.\n",
    "            running_physic_loss = 0.\n",
    "            running_data_loss = 0.\n",
    "\n",
    "            # print(f\"    Batch {i:3d}/{len(train_dataloader):3d}: train loss {running_loss:.4e}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        v_loss = 0\n",
    "        for data in validation_dataloader:\n",
    "            inputs, target, _, _, _ = data\n",
    "\n",
    "            inputs = scaler_input.transform(inputs.to(device))\n",
    "            target = scaler_target.transform(target.to(device))\n",
    "\n",
    "            ea_pred = model(inputs)\n",
    "\n",
    "            v_loss += fn_loss(ea_pred, target).item()\n",
    "\n",
    "    v_loss /= len(validation_dataloader)\n",
    "\n",
    "    writer.add_scalars('Loss per epoch', {'Training loss': last_loss, 'Validation loss': v_loss, }, epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}: Train Loss: {last_loss:.4e} - Validation Loss: {v_loss:.4e}')\n",
    "\n",
    "    if v_loss < best_v_loss:\n",
    "        best_vloss = v_loss\n",
    "        model_path = f\"{log_dir}/weights/model_{timestamp}_{epoch}\"\n",
    "        torch.save(model.state_dict(), model_path)\n"
   ],
   "id": "2149a736eeb80e2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100\n",
      "Epoch 1: Train Loss: 1.8448e-01 - Validation Loss: 1.7629e-01\n",
      "Epoch   2/100\n",
      "Epoch 2: Train Loss: 1.4096e-01 - Validation Loss: 1.3043e-01\n",
      "Epoch   3/100\n",
      "Epoch 3: Train Loss: 1.3603e-01 - Validation Loss: 1.2186e-01\n",
      "Epoch   4/100\n",
      "Epoch 4: Train Loss: 1.1200e-01 - Validation Loss: 1.0986e-01\n",
      "Epoch   5/100\n",
      "Epoch 5: Train Loss: 1.0099e-01 - Validation Loss: 9.8786e-02\n",
      "Epoch   6/100\n",
      "Epoch 6: Train Loss: 9.6123e-02 - Validation Loss: 9.0748e-02\n",
      "Epoch   7/100\n",
      "Epoch 7: Train Loss: 9.1241e-02 - Validation Loss: 9.0887e-02\n",
      "Epoch   8/100\n",
      "Epoch 8: Train Loss: 8.0505e-02 - Validation Loss: 8.1564e-02\n",
      "Epoch   9/100\n",
      "Epoch 9: Train Loss: 7.8884e-02 - Validation Loss: 7.5684e-02\n",
      "Epoch  10/100\n",
      "Epoch 10: Train Loss: 7.6216e-02 - Validation Loss: 7.7424e-02\n",
      "Epoch  11/100\n",
      "Epoch 11: Train Loss: 7.1060e-02 - Validation Loss: 7.0331e-02\n",
      "Epoch  12/100\n",
      "Epoch 12: Train Loss: 6.5600e-02 - Validation Loss: 6.4784e-02\n",
      "Epoch  13/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 30\u001B[0m\n\u001B[0;32m     26\u001B[0m target \u001B[38;5;241m=\u001B[39m scaler_target\u001B[38;5;241m.\u001B[39mtransform(target)\n\u001B[0;32m     28\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 30\u001B[0m ea_pred \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m     32\u001B[0m loss \u001B[38;5;241m=\u001B[39m fn_loss(ea_pred, target)\n\u001B[0;32m     33\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\memoire\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mlinear(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T10:57:50.927765Z",
     "start_time": "2024-12-15T22:15:41.088127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "acc = 0.\n",
    "for inputs, target, _, _, _ in test_dataloader:\n",
    "    inputs = scaler_input.transform(inputs)\n",
    "    pred = model(inputs)\n",
    "    pred = scaler_target.inverse_transform(pred)\n",
    "    break"
   ],
   "id": "7e7fc70e4febcdc4",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T10:57:50.928766600Z",
     "start_time": "2024-12-15T22:15:48.095569Z"
    }
   },
   "cell_type": "code",
   "source": "target",
   "id": "c919cb6bf34a2b44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2970e+08],\n",
       "        [1.3646e+08],\n",
       "        [2.0592e+08],\n",
       "        [7.0743e+07],\n",
       "        [1.2638e+08],\n",
       "        [3.5457e+08],\n",
       "        [1.0291e+08],\n",
       "        [2.4766e+08],\n",
       "        [3.0544e+08],\n",
       "        [2.9172e+08],\n",
       "        [3.1650e+08],\n",
       "        [3.1341e+08],\n",
       "        [2.0217e+08],\n",
       "        [2.9202e+08],\n",
       "        [1.7945e+08],\n",
       "        [6.3652e+07],\n",
       "        [1.8856e+08],\n",
       "        [9.2852e+07],\n",
       "        [3.7170e+08],\n",
       "        [2.2786e+08],\n",
       "        [1.5425e+08],\n",
       "        [2.9590e+08],\n",
       "        [1.1574e+08],\n",
       "        [1.4083e+08],\n",
       "        [9.8264e+07],\n",
       "        [8.1517e+07],\n",
       "        [7.9395e+07],\n",
       "        [1.3565e+08],\n",
       "        [3.3740e+08],\n",
       "        [2.9014e+08],\n",
       "        [3.3871e+08],\n",
       "        [3.0739e+08],\n",
       "        [2.9872e+08],\n",
       "        [2.0169e+08],\n",
       "        [2.7607e+08],\n",
       "        [9.2383e+07],\n",
       "        [1.8717e+08],\n",
       "        [1.7665e+08],\n",
       "        [1.3416e+08],\n",
       "        [7.2358e+07],\n",
       "        [1.8986e+08],\n",
       "        [1.6908e+08],\n",
       "        [2.4954e+08],\n",
       "        [2.0343e+08],\n",
       "        [2.3525e+08],\n",
       "        [3.0106e+08],\n",
       "        [1.5444e+08],\n",
       "        [1.8792e+08],\n",
       "        [1.2358e+08],\n",
       "        [1.2161e+08],\n",
       "        [3.7257e+08],\n",
       "        [2.4470e+08],\n",
       "        [1.7052e+08],\n",
       "        [1.2346e+08],\n",
       "        [1.0063e+08],\n",
       "        [4.2125e+08],\n",
       "        [2.6693e+08],\n",
       "        [1.7346e+08],\n",
       "        [8.8045e+07],\n",
       "        [5.7520e+07],\n",
       "        [3.5586e+08],\n",
       "        [9.3825e+07],\n",
       "        [4.0460e+08],\n",
       "        [9.8965e+07],\n",
       "        [3.0584e+08],\n",
       "        [1.2026e+08],\n",
       "        [2.2689e+08],\n",
       "        [4.7908e+08],\n",
       "        [1.4958e+08],\n",
       "        [1.3499e+08],\n",
       "        [2.1175e+08],\n",
       "        [1.6589e+08],\n",
       "        [2.1716e+08],\n",
       "        [9.4333e+07],\n",
       "        [2.8015e+08],\n",
       "        [1.8288e+08],\n",
       "        [7.1175e+07],\n",
       "        [1.0314e+08],\n",
       "        [5.7713e+07],\n",
       "        [2.7098e+08],\n",
       "        [7.9259e+07],\n",
       "        [2.8790e+08],\n",
       "        [2.5473e+08],\n",
       "        [1.0534e+08],\n",
       "        [7.0959e+07],\n",
       "        [1.4250e+08],\n",
       "        [2.7586e+08],\n",
       "        [5.9082e+07],\n",
       "        [3.6284e+08],\n",
       "        [2.2546e+08],\n",
       "        [2.7993e+08],\n",
       "        [1.0183e+08],\n",
       "        [1.3857e+08],\n",
       "        [2.0322e+08],\n",
       "        [2.8654e+08],\n",
       "        [1.7990e+08],\n",
       "        [2.4521e+08],\n",
       "        [1.2471e+08],\n",
       "        [3.9727e+08],\n",
       "        [3.9270e+08],\n",
       "        [3.9220e+08],\n",
       "        [2.3598e+08],\n",
       "        [2.4973e+08],\n",
       "        [1.2055e+08],\n",
       "        [2.1446e+08],\n",
       "        [1.3140e+08],\n",
       "        [5.1616e+08],\n",
       "        [2.5264e+08],\n",
       "        [3.6594e+08],\n",
       "        [2.0923e+08],\n",
       "        [2.0783e+08],\n",
       "        [9.4004e+07],\n",
       "        [2.2789e+08],\n",
       "        [4.2714e+07],\n",
       "        [1.4705e+08],\n",
       "        [2.6622e+08],\n",
       "        [1.2514e+08],\n",
       "        [7.2127e+07],\n",
       "        [1.8361e+08],\n",
       "        [8.7971e+07],\n",
       "        [9.5707e+07],\n",
       "        [1.5631e+08],\n",
       "        [1.6941e+08],\n",
       "        [2.4404e+08],\n",
       "        [1.5512e+08],\n",
       "        [6.6702e+07],\n",
       "        [1.3525e+08],\n",
       "        [2.4633e+08],\n",
       "        [1.3560e+08],\n",
       "        [1.5523e+08],\n",
       "        [1.9662e+08],\n",
       "        [1.8591e+08],\n",
       "        [2.7185e+08],\n",
       "        [1.8142e+08],\n",
       "        [1.5765e+08],\n",
       "        [1.2158e+08],\n",
       "        [8.4225e+07],\n",
       "        [4.3822e+08],\n",
       "        [2.1241e+08],\n",
       "        [3.3371e+08],\n",
       "        [3.8962e+08],\n",
       "        [1.1374e+08],\n",
       "        [3.8112e+08],\n",
       "        [3.4496e+08],\n",
       "        [1.1129e+08],\n",
       "        [2.2320e+08],\n",
       "        [2.3271e+08],\n",
       "        [1.5060e+08],\n",
       "        [3.5918e+08],\n",
       "        [2.0240e+08],\n",
       "        [9.8332e+07],\n",
       "        [1.5242e+08],\n",
       "        [2.6108e+08],\n",
       "        [4.4963e+07],\n",
       "        [4.1010e+08],\n",
       "        [1.6775e+08],\n",
       "        [4.8938e+08],\n",
       "        [1.5353e+08],\n",
       "        [1.4995e+08],\n",
       "        [3.6975e+08],\n",
       "        [3.1072e+08],\n",
       "        [2.6506e+08],\n",
       "        [1.9456e+08],\n",
       "        [1.5155e+08],\n",
       "        [4.0322e+08],\n",
       "        [1.9970e+08],\n",
       "        [2.4568e+08],\n",
       "        [8.3939e+07],\n",
       "        [4.8762e+08],\n",
       "        [3.3171e+08],\n",
       "        [1.7674e+08],\n",
       "        [1.0312e+08],\n",
       "        [1.7477e+08],\n",
       "        [3.4165e+08],\n",
       "        [2.4588e+08],\n",
       "        [3.0593e+08],\n",
       "        [3.6097e+08],\n",
       "        [1.6189e+08],\n",
       "        [2.1081e+08],\n",
       "        [1.2233e+08],\n",
       "        [1.4964e+08],\n",
       "        [3.1837e+08],\n",
       "        [2.7294e+08],\n",
       "        [6.9862e+07],\n",
       "        [3.3671e+08],\n",
       "        [1.4157e+08],\n",
       "        [1.8135e+08],\n",
       "        [8.0612e+07],\n",
       "        [2.2098e+08],\n",
       "        [1.3849e+08],\n",
       "        [1.5245e+08],\n",
       "        [4.2799e+08],\n",
       "        [1.6098e+08],\n",
       "        [3.1347e+08],\n",
       "        [2.1780e+08],\n",
       "        [2.3842e+08],\n",
       "        [4.0507e+08],\n",
       "        [3.5906e+08],\n",
       "        [2.4360e+08],\n",
       "        [8.0855e+07],\n",
       "        [1.3035e+08],\n",
       "        [1.8404e+08],\n",
       "        [3.2344e+08],\n",
       "        [1.8086e+08],\n",
       "        [2.6936e+08],\n",
       "        [2.5920e+08],\n",
       "        [8.5623e+07],\n",
       "        [2.6973e+08],\n",
       "        [7.2127e+07],\n",
       "        [2.9798e+08],\n",
       "        [3.7693e+08],\n",
       "        [6.6469e+07],\n",
       "        [4.6313e+07],\n",
       "        [3.7417e+08],\n",
       "        [2.1685e+08],\n",
       "        [1.7548e+08],\n",
       "        [1.6536e+08],\n",
       "        [3.0635e+08],\n",
       "        [1.2264e+08],\n",
       "        [9.7365e+07],\n",
       "        [6.3331e+07],\n",
       "        [2.1033e+08],\n",
       "        [3.5502e+08],\n",
       "        [3.1542e+08],\n",
       "        [2.6040e+08],\n",
       "        [3.5648e+08],\n",
       "        [2.2740e+08],\n",
       "        [3.0879e+08],\n",
       "        [1.2331e+08],\n",
       "        [5.9297e+07],\n",
       "        [2.3027e+08],\n",
       "        [2.4494e+08],\n",
       "        [1.0751e+08],\n",
       "        [1.0895e+08],\n",
       "        [1.2601e+08],\n",
       "        [1.5111e+08],\n",
       "        [1.8853e+08],\n",
       "        [2.8620e+08],\n",
       "        [1.9239e+08],\n",
       "        [1.8205e+08],\n",
       "        [1.8783e+08],\n",
       "        [1.2346e+08],\n",
       "        [7.1031e+07],\n",
       "        [3.2729e+08],\n",
       "        [1.9067e+08],\n",
       "        [2.6866e+08],\n",
       "        [4.2414e+08],\n",
       "        [3.8213e+08],\n",
       "        [2.5682e+08],\n",
       "        [2.3671e+08],\n",
       "        [3.8857e+08],\n",
       "        [7.5613e+07],\n",
       "        [1.4406e+08],\n",
       "        [4.7996e+07],\n",
       "        [1.6933e+08],\n",
       "        [1.8523e+08]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T10:57:50.943086900Z",
     "start_time": "2024-12-15T22:05:28.210923Z"
    }
   },
   "cell_type": "code",
   "source": "target[0:2]",
   "id": "fe325ef65a97dbf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40765909.4608],\n",
       "        [94472455.9233]], dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
