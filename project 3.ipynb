{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Project A3",
   "id": "ef0fc3937af4153c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.1] Assignment description\n",
    "### Gene Expression Data\n",
    "In this assignment, you will analyze gene expression data and gradually select the most informative markers for a diagnosis task. The data is made of hundreds of probeset expression values measured for a hundred different patients suffering from Glioblastoma (a form of brain cancer).\n",
    "\n",
    "In particular, we are looking for expression markers that can predict whether a patient suffers from Glioblastoma or No tumor. The data has already been preprocessed and is available below as two compressed file:\n",
    "\n",
    " - [https://inginious.info.ucl.ac.be/course/LGBIO2010/A3Q1/train.csv.bz2](train.csv.bz2)\n",
    " - [https://inginious.info.ucl.ac.be/course/LGBIO2010/A3Q1/test.csv.bz2](test.csv.bz2)\n",
    "\n",
    "These files are heavy and you should download once each file and work with the local copy on your computer.\n",
    "\n",
    "Such files can be decompressed using the following command:\n",
    "```\n",
    "bzip2 -d data.csv.bz2\n",
    "```\n",
    "Note that decompressing the data files is not mandatory (and not doing it would save space on your disk). It is only useful if you want to glance at the data first (see the important note below on how to import the data into an R session). Each decompressed .csv file contains a large two-dimensional table in which the respective entries are separated by a comma. Most data analysis softwares can take such a comma-separated file as input.\n",
    "\n",
    "The first line of each file contains the headers or names of the columns. The subsequent lines contain the actual data. Each line contains x entries corresponding to the content of the table in the following order:\n",
    "\n",
    " - A string specifying the patient ID, followed by\n",
    " - (x-2) probeset expression values, and\n",
    " - a string which can either be Glioblastoma or No tumor. This status corresponds to the two conditions of interest in the subsequent analysis.\n",
    "\n",
    "Important\n",
    "---------\n",
    "You will perform all analysis on the content of the train file, except for A3.9 where you will work with the content of the test file.\n",
    "\n",
    "Before actual analyses of the gene expression data, you will have to load the train and test data in your R session.\n",
    "\n",
    "Download both files and import them as data.frame objects in R. The read.csv() R function can be useful here. Observe that the read.csv() function can read the compressed and uncompressed versions of the files. Directly reading the compressed versions tends to be much faster.\n",
    "\n",
    "Ensure that the rows names (the patient IDs) and columns names (probesets names and \"labels\" for the last column) are actual names of the data frame and not elements of the data frame.\n",
    "\n",
    "From now on, the train and test datasets refer to the train and test data frames imported in your R session from the corresponding files."
   ],
   "id": "a747d5c4848b3020"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### [Validation] Gene expression data\n",
    "Report the dimensions (number of rows and number of columns) of the train data frame as an unnamed R vector of integer of length two, stored in a .rds file."
   ],
   "id": "e8777b55ed2b30b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.2] Probesets with largest variance\n",
    "In this exercise, you will proceed to non-specific filtering of the probesets.\n",
    "\n",
    "Rank the various probesets by increasing variance on all samples. Keep only 25% of probesets with the larger variances.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://inginious.info.ucl.ac.be/course/LGBIO2010/data/A3/VariancePlot.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "Illustration of your task. It does not correspond to the actual data you must process.\n",
    "</center>"
   ],
   "id": "7e0b97926158b71d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question 1: Generic identification of probesets with largest variance\n",
    "\n",
    "Provide an R function identifying the probesets with largest variance kept after non-specific filtering. The data and the percentage of probesets to keep are parameters of the function.\n",
    "\n",
    "Specifications\n",
    "--------------\n",
    "Your implementation:\n",
    "- must provide an R function called ns_filtering,\n",
    "- the function takes exactly two parameters:\n",
    "\n",
    "    - df: a data frame with rows corresponding to patients and columns corresponding to probesets. It can be obtained from the train data frame described in [A3.1] exercise with the following R instructions:\n",
    "``` R\n",
    "# Assuming data is the train data frame described in [A3.1]\n",
    "df = data[, -which(colnames(data) == \"labels\")]\n",
    "# Or equivalently\n",
    "df = subset(data, select = -labels)\n",
    "```  \n",
    "   - kept: a floating-point value corresponding to the fraction or percentage of probesets that are kept (typically 0.25) (if the number of probesets to keep is not an integer, round the number of probesets to keep),\n",
    "\n",
    "- returns a vector of the variance of kept probesets:\n",
    "\n",
    "    - values are sorted by decreasing variance,\n",
    "    - variance values are named after the associated probesets names,\n",
    "    - the vector contains variances of probesets that are kept after non-specific filtering.\n",
    "\n",
    "Observe that your function can be used to answer to find the top 5 probesets with the largest variance:\n",
    "```\n",
    "ns_filtering(df, 0.25)[1:5]\n",
    "```"
   ],
   "id": "b514f5f377aa8113"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T12:24:02.925891Z",
     "start_time": "2024-12-09T12:24:02.918079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ns_filtering = function(df, kept){\n",
    "\n",
    "}"
   ],
   "id": "1e8eca366aa986c5",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1534154299.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    ns_filtering = function(df, kept){\u001B[0m\n\u001B[1;37m                                     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Non-specific filtering\n",
    "Provide the variances, in decreasing order, of the 25% of probesets with largest variance after non-specific filtering of the train dataset.\n",
    "\n",
    "Important\n",
    "---------\n",
    "All subsequent exercises are performed using only the 25% of probesets with largest variance kept after non-specific filtering.\n",
    "\n",
    "The values must be reported as a named R vector of values, sorted by decreasing values, stored in a .rds file. Each value must be named after the corresponding probeset."
   ],
   "id": "26dcfbd449e035f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.3] t-Test\n",
    "In exercises [A3.3] and [A3.4] Corrections for multiple testing), you will use statistical tests to find probesets that are differentially expressed between the two conditions of interest, in the train dataset.\n",
    "\n",
    "Rank the various probesets (after non-specific filtering) using a t-test by increasing p-values to distinguish between the two conditions under study.\n",
    "<center>\n",
    "<img src=\"https://inginious.info.ucl.ac.be/course/LGBIO2010/data/A3/WelchTtest.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    "Illustration of your task. It does not correspond to the actual data you must process.\n",
    "</center>"
   ],
   "id": "e3e117f28e08e165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: Generic identification of significant probesets\n",
    "Provide an R function computing the number of probesets that are deemed significant according to a t-test with no specific correction. The data and the significance level are parameters of the function.\n",
    "\n",
    "Specifications\n",
    "--------------\n",
    "Your implementation:\n",
    "\n",
    "- must provide an R function called differential_selection,\n",
    "- the function takes exactly three parameters:\n",
    "    - data: a data frame as described in the context of the exercise [A3.1].\n",
    "    - target: an R character string corresponding to the name of the column containing the status of the patients in data.\n",
    "    - alpha: a numerical-floating point value corresponding to the significance level of the t-test (typically 0.05).\n",
    "- returns an integer value corresponding to the number of probesets that are deemed significant according to a t-test with no correction.\n",
    "\n",
    "Observe that your function can be used to answer to Question 2 using:\n",
    "```\n",
    "# data is the data frame obtained after non-specific filtering (keeping only some probesets as described in [A3.2]) of the data frame described in [A3.1]\n",
    "differential_selection(data, \"labels\", 0.05)\n",
    "```"
   ],
   "id": "a7a508010f61a662"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Fill in with your R code\n",
    "differential_selection = function(data, target, alpha){\n",
    "}"
   ],
   "id": "d6967d61e3bac789"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Significant probesets\n",
    "How many features (= probesets) are deemed significant according to such a t-test? Consider a 5% significance level and no p-value correction at this point.\n",
    "\n",
    "The expected answer is an integer (for example, 1)."
   ],
   "id": "1b5915b089c93f1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.4] Corrections for multiple testing\n",
    "How many features are considered significant after a Bonferroni correction of the original t-test (see [A3.3] exercise)? How many features are considered significant after an FDR correction of the original t-test?"
   ],
   "id": "1187363a865c30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: Generic definition of corrected p-values\n",
    "Provide an R function computing the corrected p-values of the features that are considered significant after a correction of the original test. The data and the significance level of the test, as well as the correction method, are parameters of the function.\n",
    "\n",
    "Specifications\n",
    "--------------\n",
    "Your implementation:\n",
    "- must provide an R function called correct,\n",
    "- the function takes exactly four parameters:\n",
    "\n",
    "    - data: a data frame as described in the context of the exercise [A3.1].\n",
    "    - target: an R character string corresponding to the name of the column containing the status of the patients in data.\n",
    "    - alpha: a numerical floating-point value corresponding to the significance level of the t-test (typically 0.05).\n",
    "    - method: an R character string corresponding to the correction to consider (acceptable values are bonferroni or fdr).\n",
    "\n",
    "- returns a named vector of the corrected p-values:\n",
    "\n",
    "    - values are the corrected p-values of the kept features,\n",
    "    - the name of each element is the name of the associated probeset,\n",
    "    - the values are sorted according to increasing corrected p-values.\n",
    "\n",
    "Observe that your function can be used to answer to Question 2 and Question 3 using:\n",
    "\n",
    "```\n",
    "# data is the data frame described in [A3.1] after non-specific filtering in [A3.2]\n",
    "Q2 = correct(data, \"labels\", 0.05, \"bonferroni\")\n",
    "Q3 = correct(data, \"labels\", 0.05, \"fdr\")\n",
    "```"
   ],
   "id": "6595c1743c443ed9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Fill in with your R code\n",
    "correct = function(data, target, alpha, method){\n",
    "\n",
    "}"
   ],
   "id": "7af17ee6df8c6aff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Bonferroni correction\n",
    "Report an R vector of the corrected p-values of the features that are considered significant after Bonferroni correction of the original t-test. Consider a significance level of 5%. The vector is named after the corresponding probesets names. Corrected p-values should be ordered by increasing value.\n",
    "\n",
    "Your result should be submitted as a .rds file."
   ],
   "id": "f4477807e6a6e974"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fcb6ad8b40ba43b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 3: FDR correction\n",
    "Report an R vector of the corrected p-values of the features that are considered significant after FDR correction of the original t-test. Consider a significance level of 5%. The vector is named after the corresponding probesets names. Corrected p-values should be ordered by increasing value.\n",
    "\n",
    "Your result should be submitted as a .rds file."
   ],
   "id": "915aeb241ae172c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbd7d51f51767925"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 4: Correction methods\n",
    "You considered two alternative approaches to correct for multiple testing, namely Bonferroni and FDR. Select the valid propositions below.\n",
    "- [ ] The Bonferroni correction is less conservative than the FDR correction: more probesets are considered differentially expressed with the Bonferroni correction\n",
    "- [ ] The top-one most significant probeset is guaranteed to be the same after either Bonferroni or after FDR correction\n",
    "- [ ] The Bonferroni-corrected p-values are lower than the FDR-corrected p-values\n",
    "- [ ] The FDR-corrected p-values are lower than the Bonferroni-corrected p-values\n",
    "- [ ] The FDR correction is less conservative than the Bonferroni correction: more probesets are considered differentially expressed with the FDR correction"
   ],
   "id": "eddb5cc1750d802f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 5: Differentially expressed probesets\n",
    "Report an R vector of the uncorrected p-values of the 50 most differentially expressed features. The vector is named after the corresponding probesets' names. The p-values should be ordered by increasing value.\n",
    "\n",
    "Your result should be submitted as a .rds file."
   ],
   "id": "e4b31f71c2523e2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f962b74b2d0cba77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.5] Heatmaps\n",
    "In exercises [A3.5], [A3.6], and [A3.7], you will use heatmaps and 2-D plots to get an idea of the possible associations among some of the variables and the distribution of part of the data.\n",
    "\n",
    "A heatmap illustrates two hierarchical clusterings, respectively along the features (= probesets) and along the samples.\n",
    "\n",
    "Check the heatmap.2 function of the gplots R package to produce heatmaps.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://inginious.info.ucl.ac.be/course/LGBIO2010/data/A3/Heatmap.jpg\" width=500 height=500>\n",
    "\n",
    "Illustration of your task. The heatmap does not correspond to the actual data you must process.\n",
    "</center>"
   ],
   "id": "8ea2a69bfa445493"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: Data transformation\n",
    "Centering and normalizing features to unit variance is a common data transformation. Select the appropriate motivation(s) for such a data transformation, in the context of descriptive analysis, among the propositions below.\n",
    "\n",
    "- [ ] To ensure normality of the distribution, ensuring that normality assumptions of statistical tests are met\n",
    "- [ ] To ensure that variables present the same scale, ensuring similar contribution weights of the variables in subsequent analyses\n",
    "- [ ] To ensure that variables present the same distribution, ensuring that variables represent similar underlying models\n",
    "- [ ] To ensure that outliers have a reduced influence, ensuring that the conclusions are not driven by these outliers"
   ],
   "id": "45db2000e7abbf0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc9ac8f6ba7921f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Heatmap\n",
    "Report a heatmap of all samples along the 50 most differentially expressed features (according to your analysis on the data after non-specific filtering).\n",
    "\n",
    "- Use some color coding [1] to label each sample with its respective condition (Glioblastoma or No tumor).\n",
    "- Ensure that the plot contains appropriate titles and is readable [2].\n",
    "\n",
    "The submitted file should be a .png file.\n",
    "\n",
    "[1]\tCheck the RowSideColors or ColSideColors arguments of the heatmap.2 function.\n",
    "[2]\tConsider setting the trace argument to none."
   ],
   "id": "d73f7d320a3733fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "726e20ef5544afc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 3: [Open question] Graph description and analysis\n",
    "Regarding the file submitted in Question 2:\n",
    "\n",
    "- Describe the data transformation (if any) used before actually generating the graph, or explicitly state that you did not transform the data (if you did not),\n",
    "- Briefly describe the heatmap,\n",
    "- Discuss to which extent the samples are clustered consistently with the conditions of interest,\n",
    "- Explain the reason(s) of possible difference(s), if any, or why the clustering is fully consistent with the conditions of interest."
   ],
   "id": "77d01f8413316498"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#Answer either in English or in French",
   "id": "92a2d0ddb12cb17b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.6] 2-D plot of most discriminative features\n",
    "You identified probesets that are differentially expressed between the two conditions of interest in exercises [A3.3], and [A3.4]. Can you actually observe different distributions of the most discriminative features between these conditions?\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inginious.info.ucl.ac.be/course/LGBIO2010/data/A3/2Dplot.png\" width=500 height=500>\n",
    "\n",
    "Illustration of your task. The graph does not correspond to the actual data you must process.\n",
    "</center>"
   ],
   "id": "cc594e6fb7967a32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: 2-D plot of most discriminative features\n",
    "Report a 2-D plot of all samples along the two most discriminative features according to your differential expression analysis.\n",
    "\n",
    "- Use some specific coding (e.g. a color code) to label each sample with its respective condition.\n",
    "- Report the most discriminating probeset along the x-axis and the second best along the y-axis.\n",
    "- Report the names of the chosen features along the x- and y-axis of your plot.\n",
    "- Ensure that the plot is readable.\n",
    "\n",
    "The submitted file should be a .png file."
   ],
   "id": "a6933b0d5c691e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa00131ee2a96d14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Expression of the most discriminating probeset\n",
    "Determine whether the two most discriminative features, according to your differential expression analysis, are under-expressed, over-expressed or if they tend to present similar expression (i.e. their mean expression values do not significantly differ after FDR correction and a significance threshold alpha = 5%).\n",
    "\n",
    "Report an R vector with named values (considering the probesets as names). Values can be either:\n",
    "\n",
    "- 1 if the Glioblastoma patients present over-expression,\n",
    "- -1 if the Glioblastoma patients present under-expression,\n",
    "- 0 if the Glioblastoma patients present similar expression to No tumor patients.\n",
    "\n",
    "Report the values for the two most discriminative features considering your differential expression analysis."
   ],
   "id": "45f67d047ae12455"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "752453df1cf5cf23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.7] 2-D plot of least discriminative features\n",
    "You identified probesets that are differentially expressed between the two conditions of interest in exercises [A3.3], and [A3.4]. Can you actually observe different distributions of the least discriminative features (among all features kept after non-specific filtering, see [A3.2]) between these conditions?\n",
    "\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inginious.info.ucl.ac.be/course/LGBIO2010/data/A3/2Dplot.png\" height=500 width=500>\n",
    "\n",
    "Illustration of your task. The graph does not correspond to the actual data you must process.\n",
    "</center>"
   ],
   "id": "ca41f518bb9fc08b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: 2-D plot of least significant features\n",
    "Report a 2-D plot of all samples along the two least discriminative features to distinguish between both conditions.\n",
    "\n",
    "- Use some specific coding (e.g. a color code) to label each sample with its respective condition.\n",
    "- Report the least discriminating probeset along the x-axis and the second least discriminating one along the y-axis.\n",
    "- Report the names of the chosen features along the x- and y-axis of your plot.\n",
    "- Ensure that the plot is readable.\n",
    "\n",
    "The submitted file should be a .png file."
   ],
   "id": "bbb269239db0d4ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6e5797351adf9ae1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Question 2: Expression of the least discriminating probesets\n",
    "Determine whether the two least discriminative features are under-expressed, over-expressed or if they tend to present similar expression (i.e. their mean expression values do not significantly differ after FDR correction and a significance threshold alpha = 5%).\n",
    "\n",
    "Report an R vector with named values (considering the probesets as names). Values can be either:\n",
    "\n",
    "- 1 if the Glioblastoma patients present over-expression,\n",
    "- -1 if the Glioblastoma patients present under-expression,\n",
    "- 0 if the Glioblastoma patients present similar expression to No tumor patients.\n",
    "\n",
    "Report the values for the two least discriminative features to distinguish between both conditions as .rds file."
   ],
   "id": "94cc7c76694c928f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "283035ee1ce810b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.8] Support Vector Machines\n",
    "In exercises [A3.8], and [A3.9], you will fit a linear SVM on a training set and evaluate the model on a test set.\n",
    "\n"
   ],
   "id": "6e154f4310ad77b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: SVM weights\n",
    "Fit a linear SVM on the training using all probesets obtained after non-specific filtering (see [A3.2]). We recommend the LiblineaR R package. Each feature should be centered and normalized to unit variance before the actual SVM training.\n",
    "\n",
    "Report an R data frame with the 10 most important features according to the absolute weight values of such a linear model. The data frame should be made of 10 rows named after the probeset names. The data frame should be made of two columns, named respectively \"Weight\" and \"Rank\". The \"Weight\" column should contain the absolute weight value of the 10 most important features according to the absolute weight values of the linear model. The \"Rank\" column should contain the respective ranks of those features according to the ranking of p-values computed in Question [A3.3] .\n",
    "\n",
    "You are invited to consult the documentation of the LiblinearR R package. To build an SVM model, the type argument should be equal to 2. Once a model has been built from a training sample, the model parameters can easily be accessed as model$W[1,]. Such model paremeters also include an intercept or bias term, by default. You are expected to stick to this default setting when fitting the SVM. Yet, when reporting the 10 most important features, only the 10 most important actual probesets should be reported (no matter what is the fitted bias term).\n",
    "```\n",
    "#Build a model from a training sample\n",
    "model <- LiblineaR(...)\n",
    "#Access the model parameters\n",
    "model$W[1,]\n",
    "```\n",
    "\n",
    "Allowed extensions: .rds"
   ],
   "id": "60e8275b70252cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c29cb3c59b1d4f3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Question 2: [Open question] SVM weights - R code\n",
    "Submit below the R code you implemented, including possible calls to some existing R package(s) through the library(...) function, to answer previous question."
   ],
   "id": "977f9e1d65a2882c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Fill in with your R code below",
   "id": "a1536e244d6e812"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## [A3.9] Prediction\n",
    "Compute the labels (either Glioblastoma or No tumor) of the test samples predicted by the linear SVM estimated on the training set."
   ],
   "id": "491c60928b6f430f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 1: Confusion matrix\n",
    "Report a confusion matrix between predicted and true labels on the test set.\n",
    "\n",
    "Important notes:\n",
    "----------------\n",
    "You must now work on the test set and no longer on the training set.\n",
    "The SVM model produced in exercise [A3.8] is built with a reduced set of probesets and these probesets have been scaled before fitting the SVM. As such, remove from the test set all probesets that have been removed by the non-specific filtering (see [A3.2] ). Then, normalize each remaining probeset (from the test set) using the mean and variance scaling parameters computed from the training set. Check the use of the scale function in the examples included in the LiblineaR documentation.\n",
    "Upload an R table stored in a .rds file. The table contains the predictions on the rows and the true labels on the columns. The first row and the first column are called Glioblastoma. The second row and the second column are called No tumor.\n",
    "\n",
    "As an example, suppose the following:\n",
    "\n",
    "- prediction: c(\"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"Glioblastoma\", \"No tumor\")\n",
    "- true labels: c(\"Glioblastoma\", \"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"No tumor\")\n",
    "\n",
    "To produce the associated table, you would use the following R instructions:\n",
    "\n",
    "```\n",
    "prediction = c(\"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"Glioblastoma\", \"No tumor\")\n",
    "truth = c(\"Glioblastoma\", \"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"No tumor\")\n",
    "res = table(prediction, truth)\n",
    "```"
   ],
   "id": "cfbd944499fe1617"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b4bbdefcb12e3488"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 2: Generic classification accuracy\n",
    "Provide an R function computing the classification accuracy of a model. The confusion matrix is a parameter of the function.\n",
    "\n",
    "Specifications\n",
    "--------------\n",
    "Your implementation:\n",
    "\n",
    "- must provide an R function called classification_accuracy,\n",
    "- the function takes exactly one parameter:\n",
    "    - confusion_matrix: a confusion matrix as described in the previous Question.\n",
    "- returns a floating-point value in the range [0.0,1.0] corresponding to the classification accuracy of the model given the provided prediction.\n",
    "\n",
    "Observe that your function can be used to answer to Question 3. To compute the classification accuracy of the example provided in Question 1, you would use:\n",
    "```\n",
    "predictions = c(\"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"Glioblastoma\", \"No tumor\")\n",
    "truth = c(\"Glioblastoma\", \"Glioblastoma\", \"Glioblastoma\", \"No tumor\", \"No tumor\")\n",
    "accuracy = classification_accuracy(table(predictions, truth))\n",
    "```"
   ],
   "id": "af239736493f4205"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Fill in with your R code\n",
    "classification_accuracy = function(confusion_matrix){\n",
    "\n",
    "}"
   ],
   "id": "1292d4584dacad3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Question 3: Classification accuracy\n",
    "Report the classification accuracy of the SVM on the test (report a floating-point number in the range [0.0,1.0] with at least two decimals)."
   ],
   "id": "4e1edffacd00788d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e1c244caf97c58b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
